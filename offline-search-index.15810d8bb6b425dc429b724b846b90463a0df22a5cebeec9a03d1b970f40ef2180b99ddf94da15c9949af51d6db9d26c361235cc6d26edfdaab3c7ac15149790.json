[{"body":"Documentation https://kubernetes.io/docs/concepts/\nOverview  Kubernetes Master  クラスタ内に１つ存在するマスターノード。ノード上で、kube-apiserver, kube-controller-manager, kube-schedulerの3プロセスが動作する。   マスター以外のノードで動くプロセス:  kubelet kube-proxy    基本的なオブジェクト:\n Pod Service Volume Namespace  Kubernetesでは、複数の仮想的なクラスタを同じ物理クラスタ上に構築することができる。この仮想クラスタのことを Namespace と呼ぶ。    より高次の概念として Controller と呼ばれるものがある。\nこれは基本オブジェクト上に構築され、以下のような便利な機能を提供する:\n ReplicaSet \u0026hellip; Replication Controllerの後継。 Deployment \u0026hellip; PodやReplicaSetの状態を宣言的に記述することを可能にする。 StatefulSet \u0026hellip; v1.8でbeta. Deployment同様Podを管理するが、それぞれのPodを異なる個体と認識する。 DaemonSet \u0026hellip; ノード上でPodのコピーを動かす。典型的なユースケースとしては、cephやfluentd, collectdなどが挙げられる。 Job \u0026hellip; Podを実行し、正常に完了するまでをトラッキングする。定められた回数、正常に完了したら、Jobも完了となる。  Components https://kubernetes.io/docs/concepts/overview/components/\nMaster Components  kube-apiserver  Kubernetesを制御するフロントAPI. 水平スケール可能。参考: Building High-Availability Clusters | Kubernetes   etcd \u0026hellip; クラスタの管理データが保存されるので、バックアップすべし。 kube-controller-manager  Controllerをバックグラウンドのスレッドで動かす。 個々のControllerは論理的には独立した存在だが、複雑性を避けるため同一のバイナリで単一プロセスとして動作している。 以下のControllerが含まれる:  Node Controller Replication Controller Endpoints Controller Service Account \u0026amp; Token Controller     cloud-controller-manager \u0026hellip; v1.6でalpha. クラウド基盤とやりとりするControllerを動かす。 kube-scheduler \u0026hellip; 生成されるPodを監視し、Podを動作させるノードを決定する。 addons \u0026hellip; クラスタの機能を提供するPod群。これらのPodは kube-system という Namespace に作られる。  DNS Web UI (Dashboard) Container Resource Monitoring Cluster-level Logging    Node Components  kubelet \u0026hellip; マスターと通信するエージェントプロセス。 kube-proxy \u0026hellip; ノード上でKubernetes APIによって定義されたサービスを媒介するネットワークプロキシ。 docker, rkt \u0026hellip; コンテナランタイム supervisord \u0026hellip; ノード上でdockerやkubeletを動かし続ける。 fluentd \u0026hellip; cluster-level loggingを実現する。  Pods Podが起動できない理由:\n OutOfMemory, OutOfCpu \u0026hellip; Nodeのリソースが足りない  参考:\n Node上へのPodのスケジューリング - Kubernetes  Podの終了 https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods\n参考:\n Kubernetes: 詳解 Pods の終了 - Qiita KubernetesでRollingUpdateするためのPodの安全な終了 | SIOS Tech. Lab  CrashLoopBackOff 発生条件:\n memory limits以上を使おうとしてOOMで殺され、繰り返し再起動されるとき  再起動間隔はexponential backoffで延びる    参考:\n KubernetesのResource RequestsとResource Limitsについて - Qiita  Services  https://kubernetes.io/docs/concepts/services-networking/service/ https://cloud.google.com/kubernetes-engine/docs/concepts/service  Kubernetesクラスタ内では、複数のPodを束ねてServiceにしている。 Serviceを使用すると、メンバーPodのIPアドレスが変更されても、Serviceが存続している間に固定のIPアドレスを取得できる。\n Label Selector \u0026hellip; サービスを識別するためのラベルとそのセレクタ。 Endpoints API \u0026hellip; Service内のPodの変更に伴って更新される。  Service定義ファイルのサンプル:\nkind:ServiceapiVersion:v1metadata:name:my-servicespec:selector:app:MyAppports:- protocol:TCPport:80targetPort:9376これはKubernetesクラスタ内で my-service という名前でアクセスできる。\n参考:\n Service | Kubernetes Engine のドキュメント | Google Cloud Kubernetes道場 9日目 - Serviceについて - Toku\u0026rsquo;s Blog  Serviceのtype https://cloud.google.com/kubernetes-engine/docs/concepts/service?hl=ja#types_of_services\n ClusterIP （デフォルト） \u0026hellip; クラスタ内で固定IPアドレスを獲得 NodePort \u0026hellip; 指定された1つ以上の nodePort 値を利用して、ノードのIPアドレスを通じてアクセス可能になる LoadBalancer \u0026hellip; ネットワークロードバランサを介したアクセスを提供 ExternalName \u0026hellip; See below Headless  ExternalName https://kubernetes.io/ja/docs/concepts/services-networking/service/#externalname\n外部から参照できるDNS名を提供する。\nこの機能を使うには、GKEなどのように、KubernetesにDNSコンポーネントが導入されている必要がある。\nExample:\napiVersion:v1kind:Servicemetadata:name:my-servicenamespace:prodspec:type:ExternalNameexternalName:my.database.example.comリソース管理 Pod Eviction Documents:\n https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/  メモ:\n ノードのメモリが不足すると、Podがevictされることがある メモリ使用量の大きなPodからeviction対象になる memoryのrequets/limitsを適切に設定しておくこと  参考:\n Kubernetes pod evictedとスケジューリングの問題を理解する | Sysdigブログ - コンテナ・Kubernetes環境向けセキュリティ・モニタリング プラットフォーム ノード - Kubernetes  ","excerpt":"Documentation https://kubernetes.io/docs/concepts/\nOverview  Kubernetes Master  クラスタ内に１つ存在するマスターノード。 …","ref":"/tech-notes/a/software/k8s/concept/","title":"Concept"},{"body":"Best Practices  Configuration Best Practices | Kubernetes  kubeconfig クラスタ認証情報を保存するYAMLファイル。\nkubectl の設定ファイル。\nデフォルトのPATHは $HOME/.kube/config\n参考:\n Configure Access to Multiple Clusters - Kubernetes  Container コマンド/引数の定義 See https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes\nExample:\napiVersion:v1kind:Podmetadata:name:command-demolabels:purpose:demonstrate-commandspec:containers:- name:command-demo-containerimage:debiancommand:[\u0026#34;printenv\u0026#34;]args:[\u0026#34;HOSTNAME\u0026#34;,\u0026#34;KUBERNETES_PORT\u0026#34;]restartPolicy:OnFailureliveness/readiness probes  Configure Liveness, Readiness and Startup Probes - Kubernetes  ヘルスチェック的なもの。\n参考:\n Kubernetes道場 10日目 - LivenessProbe / ReadinessProbeについて - Toku\u0026rsquo;s Blog  Lifecycle Hooks https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/\n以下のフックを仕込むことで、コマンド実行などが可能。\n PostStart PreStop \u0026hellip; 終了直前に実行される  詳細な仕様はAPIリファレンスを見よ。\n設定例:\napiVersion:v1kind:Podmetadata:name:lifecycle-demospec:containers:- name:lifecycle-demo-containerimage:httpdlifecycle:preStop:exec:command:[\u0026#34;sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;sleep 2; httpd -k graceful-stop; sleep 30\u0026#34;]terminationGracePeriodSeconds:40参考:\n pod(Kubernetes)のlifecycle.prestopの挙動 - １クール続けるブログ Kubernetes道場 6日目 - Init Container / Lifecycleについて - Toku\u0026rsquo;s Blog  Pods Affinity  Node上へのPodのスケジューリング - Kubernetes#AffinityとAnti-Affinity  参考:\n Kubernetes道場 18日目 - Affinity / Anti-Affinity / Taint / Tolerationについて - Toku\u0026rsquo;s Blog KubernetesのNode AffinityとInternal Pod Affinityを使ってPodを高度スケジューリングする - Kekeの日記 KubernetesのNode Affinity, Inter-Pod Affinityについて - Qiita  Deployment  https://kubernetes.io/ja/docs/concepts/workloads/controllers/deployment/  参考:\n Kubernetes道場 8日目 - ReplicaSet / Deploymentについて - Toku\u0026rsquo;s Blog  spec strategy 更新戦略。\nExample:\nspec:strategy:rollingUpdate:maxSurge:25%maxUnavailable:25%type:RollingUpdate上はデフォルト値。\n type \u0026hellip; Recreate を選ぶと既存の全てのPodは新しいPodが作成される前に削除される maxSurge \u0026hellip; 理想状態のPod数を超えて作成できる最大のPod数/割合。絶対数も指定可能 maxUnavailable \u0026hellip; 更新中に利用不可となる最大のPod数/割合。絶対数も指定可能  本番ではキャパシティが低下しないように 0 にしておいた方が良さそう。    参考:\n KubernetesのRolling updateを安全に行う - Qiita Zero Downtime Deployment with Kubernetes  ConfigMaps \u0026amp; Secrets 参考:\n Kubernetes道場 11日目 - ConfigMap / Secretについて - Toku\u0026rsquo;s Blog Kubernetes: ConfigMap / Secret の内容を一度に環境変数として読み込む (envFrom) - Qiita  ConfigMaps Secretsと似ているが、こちらは値をencodeせずに平文でYAMLに書くので、普通の設定ファイル的な位置づけ。\n公式サイトにいくつかのガイドやサンプルがある:\n Use ConfigMap Data in Pods | Kubernetes Configure Containers Using a ConfigMap | Kubernetes Configuring Redis using a ConfigMap | Kubernetes  Secrets https://kubernetes.io/docs/concepts/configuration/secret/\nパスワードなどテキストをbase64でencodeして保存する。\n暗号化の機能もある？\nPodから環境変数として読み込むという使い方をすることが多いようだ。\n参考:\n Kubernetes Secrets の紹介 – データベースのパスワードやその他秘密情報をどこに保存するか？ – ゆびてく  Secretsの作成 例1) テキストファイルから作成\necho -n \u0026#39;admin\u0026#39; \u0026gt; ./username.txt echo -n \u0026#39;1f2d1e2e67df\u0026#39; \u0026gt; ./password.txt kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txt 例2) 自分で定義ファイル(YAML)を作る\necho -n \u0026#39;admin\u0026#39; | base64 YWRtaW4= echo -n \u0026#39;1f2d1e2e67df\u0026#39; | base64 MWYyZDFlMmU2N2Rm ## secret.yamlapiVersion:v1kind:Secretmetadata:name:mysecrettype:Opaquedata:username:YWRtaW4=password:MWYyZDFlMmU2N2Rmkubectl apply -f ./secret.yaml ResourceQuotas https://kubernetes.io/docs/concepts/policy/resource-quotas/\nExample:\napiVersion:v1kind:ResourceQuotametadata:name:compute-resourcesspec:hard:requests.cpu:\u0026#34;1\u0026#34;requests.memory:1Gilimits.cpu:\u0026#34;2\u0026#34;limits.memory:2Gi適用例:\nkubectl create -f ./compute-resources.yaml --namespace=myspace Note:\n ResourceQuotaを設定したnamespaceに属する全Podの合計値が上限になる cpu, memory以外も色々ある  LimitRange https://kubernetes.io/docs/concepts/policy/limit-range/\nExample:\napiVersion:v1kind:LimitRangemetadata:name:limit-mem-cpu-per-containerspec:limits:- max:cpu:\u0026#34;800m\u0026#34;memory:\u0026#34;1Gi\u0026#34;min:cpu:\u0026#34;100m\u0026#34;memory:\u0026#34;99Mi\u0026#34;default:cpu:\u0026#34;700m\u0026#34;memory:\u0026#34;900Mi\u0026#34;defaultRequest:cpu:\u0026#34;110m\u0026#34;memory:\u0026#34;111Mi\u0026#34;type:Container namespaceに対して設定する cpu/memoryのrequests/limitsの下限、上限、デフォルト値を設定できる  Topics CPU/Memoryの割り当て 基本:\n Podは、cpu/memory requests以上の空きリソースを持つノードにスケジュールされる コンテナのcpu利用量がlimit値を越えるとスロットルされる = パフォーマンス劣化する コンテナのmemory利用量がlimit値を越えるとOOM Killerで殺される。再起動できるときは再起動される Podが複数のコンテナで構成される場合、リソース指定値は全コンテナの合計値になる requestsを指定しないとデフォルト値になる limitsを指定しないとノードで利用可能な最大値になる  Tips:\n コンテナのcpu/memoryのrequestsより大きなlimitsを指定することで、突発的な負荷に耐えられるようになり、かつ、適切に制限をかけられる  ベストプラクティス:\n NamespaceでResourceQuotasやLimitRangeを設定すると良い  参考:\n コンテナおよびPodへのCPUリソースの割り当て - Kubernetes コンテナおよびPodへのメモリーリソースの割り当て - Kubernetes 例を交えてKubernetesのリミットとリクエストを理解する | Sysdigブログ - コンテナ・Kubernetes環境向けセキュリティ・モニタリング プラットフォーム Kubernetes best practices: Resource requests and limits | Google Cloud Blog 開発者のベスト プラクティス - Azure Kubernetes Service (AKS) でのリソース管理 | Microsoft Docs  ","excerpt":"Best Practices  Configuration Best Practices | Kubernetes  kubeconfig クラスタ認証情報を保存するYAMLファイル。\nkubectl …","ref":"/tech-notes/a/software/k8s/config/","title":"Configuration"},{"body":"Topics 変数や関数の命名 便利なサービス:\n https://codic.jp/  参考になる記事:\n ブール値を返すメンバー関数の命名規則  言語の習得 a to z ある言語を一通り学ぶということがどういうことかをまとめる。\n 文法  ソースコードの構造、形式  ステートメント  区切り文字   コメント 式 演算子 キーワード リテラル  数値, 文字列, ヒアドキュメント, etc.   その他記号   数値演算 プリミティブな文字列処理  結合, 分解, 書式, \u0026hellip;   型 制御構文  ループ 条件分岐   例外処理 関数 構造体, 拡張型 オブジェクト 外部ファイルの利用   言語機能  基本的なデータ型  配列 連想配列(マッピング構造体, ハッシュ)   日付、時刻、時間 標準入出力 ファイル入出力 テキスト処理  正規表現 エンコーディング マルチバイト文字対応   オブジェクト指向プログラミング  クラス, メソッド 継承 Mixin オーバーライド, オーバーロード   バイナリ処理 並行処理 関数型プログラミング  高階関数 curry化 クロージャ, 無名関数, lambda式   ライブラリの利用  標準ライブラリ 3rd Partyのライブラリ   テスト メタプログラミング  リフレクション ジェネリクス     実行  対話IFによる実行  REPL     テスト  単体テスト フレームワーク, ライブラリ   典型的な問題解決  乱数 典型的アルゴリズム  ソート, ハッシュ表, etc.   典型的データ構造  連結リスト, 木, グラフ, etc.     プログラミング手法  ダックタイピング   デバッグ プロファイリング 内部構造  実行プロセス  スレッド   コンパイラ インタープリタ VM GC  アルゴリズム     ソフトウェア開発  CLI バッチ処理 デーモン ライブラリ Webアプリケーション システムプログラミング etc.   開発環境・ツール  エディタ IDE   コミュニティ  Child Pages ","excerpt":"Topics 変数や関数の命名 便利なサービス:\n https://codic.jp/  参考になる記事:\n ブール値を返すメンバー関数の命名規則  言語の習得 a to z ある言語を一通り学ぶとい …","ref":"/tech-notes/a/program/lang/","title":"プログラム言語"},{"body":"IT技術についての個人的なメモを書くサイトです。\n主に自分用のものですが、閲覧は自由です。\n誤りなどありましたら、なんらかの方法でお知らせ頂ければ対応するかもしれません。\nNOTE progrhyme\u0026rsquo;s Tech Wikiの後継となるサイトです。  作り方 静的サイトジェネレーターのHugoを使っています。\nテーマはDocsyです。\nソースコードはGitHubにあります。\nページ構成について 雑なメモはMemorandumの下に置いています。\nそれ以外も雑で気まぐれですが、なんとなく分類しています（予定）。 ときどきページ構成を工事することもあります。\nAbout Me  Profile Site Twitter: @progrhyme GitHub: @progrhyme progrhyme\u0026rsquo;s tech blog  姉妹サイト  progrhyme\u0026rsquo;s Wiki \u0026hellip; こちらもゆくゆくはGoogleサイト外に移行するかもしれませんが、2020-04-25現在は未定です。  ","excerpt":"IT技術についての個人的なメモを書くサイトです。\n主に自分用のものですが、閲覧は自由です。\n誤りなどありましたら、なんらかの方法でお知らせ頂ければ対応するかもしれません。\nNOTE …","ref":"/tech-notes/a/","title":"progrhyme's Tech Notes"},{"body":"Plugins File Watchers ファイルを監視して自動で実行されるアクションを設定できる。\n例えば、ファイルの変更を監視してコードフォーマッタを適用するとか。\nファイル監視 - 公式ヘルプ | IntelliJ IDEA\nHow to Upgrade Ubuntu  2020年に2018年版から2020.1にアップデートしたときのログ 2018年に2017年版から2018.1にアップデートしたときのログ  ","excerpt":"Plugins File Watchers ファイルを監視して自動で実行されるアクションを設定できる。\n例えば、ファイルの変更を監視してコードフォーマッタを適用するとか。\nファイル監視 - …","ref":"/tech-notes/a/program/idea/","title":"IntelliJ IDEA"},{"body":"Documentation 公式:\n https://docs.docker.com/ リファレンス: https://docs.docker.com/reference/  Dockerfile dockerコマンド    3rd Party:\n Docker ドキュメント日本語化プロジェクト — Docker-docs-ja  Getting Started 入門コンテンツ:\n Engine tutorials | Docker Documentation  Child Pages ","excerpt":"Documentation 公式:\n https://docs.docker.com/ リファレンス: https://docs.docker.com/reference/  Dockerfile …","ref":"/tech-notes/a/software/docker/","title":"Docker"},{"body":"Getting Started 入門コンテンツ:\n Introduction to Bash bash 入門 - se.cite.ehime-u.ac.jp bash 入門 - rat.cis.k.hosei.ac.jp  コーディング規約:\n Shell Style Guide \u0026hellip; Google bashコーディング規約参考 - Qiita  Documents 公式  Man page of BASH Bash Reference Manual CHANGES: https://tiswww.case.edu/php/chet/bash/CHANGES リリースノート的なもの: https://tiswww.case.edu/php/chet/bash/NEWS  非公式  Bash changes [Bash Hackers Wiki] ★Bash scripting \u0026hellip; 便利な Bash の小技いろいろ bash 配列まとめ - Qiita  配列の操作いろいろ    プロンプトについて:\n PS1とPROMPT_COMMAND, GNU screenでの活用も  bashコマンド Examples:\nbash -n script.sh # シンタックスチェック 参考:\n シェルスクリプトのlint - Qiita  Syntax リダイレクト Qiitaにまとめを書いた:\n Bashの入出力リダイレクトまとめ - Qiita  参考:\n bash: 標準出力、標準エラー出力をファイル、画面それぞれに出力する方法 - Qiita 覚えてると案外便利なBashのリダイレクト・パイプの使い方9個 | 俺的備忘録 〜なんかいろいろ〜  ヒアドキュメント ※POSIX標準ではないか。少なくともkshでは動かなさそう。\nExamples:\ncat \u0026lt;\u0026lt; EOS \u0026gt; cat.out foo bar baz EOS BODY=\u0026#34;$(cat \u0026lt;\u0026lt; EOS Dear Ken, I\u0026#39;m so happy to write this message. I\u0026#39;ll be back soon! EOS )\u0026#34; ヒアドキュメントは文字列リテラルではなく、標準入力らしい。\n参考:\n bashのヒアドキュメントを活用する - Qiita  正規表現 POSIXか、EREなのだと思う。\nSYNOPSIS:\nif [[ \u0026#34;$str\u0026#34; =~ ^ba*r$ ]]; then echo match end ## マッチしないことの検査 if [[ ! \u0026#34;$str\u0026#34; =~ ^ba*r$ ]]; then echo not match end 参考:\n https://sites.google.com/site/progrhymetechwiki/program/regexp case 文の使用方法 | UNIX \u0026amp; Linux コマンド・シェルスクリプト リファレンス [Bash]正規表現マッチした部分文字列を再利用する方法 · DQNEO起業日記 bashでif に正規表現を使った文字列マッチ条件分岐 - それマグで！  How-to プロンプト(PS1)の変更 カスタマイズしたくなったときに見るページ:\n bashのプロンプトを変更するには Linuxで、bash プロンプトを素敵で実用的なものに変更する  ","excerpt":"Getting Started 入門コンテンツ:\n Introduction to Bash bash 入門 - se.cite.ehime-u.ac.jp bash 入門 - …","ref":"/tech-notes/a/cli/bash/","title":"Bash"},{"body":"Atlassian社が提供しているソースコードのホスティングサービス。\nJIRAなど他のAtlassian製品との連携が強み（だと思う）。\n提供形態  クラウド \u0026hellip; Bitbucket Cloud セルフホスト \u0026hellip; オンプレミス  Bitbucket Server \u0026hellip; 単一サーバ Bitbucket Datacenter \u0026hellip; クラスタ構成    Documentation  Bitbucket Cloud documentation - Atlassian Documentation 邦訳: Bitbucket Cloud ドキュメント - アトラシアン製品ドキュメント  Webhook を管理する - アトラシアン製品ドキュメント    Pipelines 付属のCI/CDツール。\n製品ページ\nDocumentation  Build, test, and deploy with Pipelines 邦訳: Pipelines を使用したビルド、テスト、およびデプロイ  YAML アンカー - アトラシアン製品ドキュメント Bitbucket Pipelines の FAQ - アトラシアン製品ドキュメント   デモリポジトリ: https://bitbucket.org/bitbucketpipelines/workspace/projects/DOC  プルリクエストで実行する ドキュメント: bitbucket-pipelines.yml の設定 - アトラシアン製品ドキュメント\npull-requests というキーワードによって、PRをトリガーとするパイプライン処理を記述できる。\nExample:\npipelines:pull-requests:\u0026#39;**\u0026#39;:#this runs as default for any branch not elsewhere defined- step:script:- ...feature/*:#any branch with a feature prefix- step:script:- ...参考:\n プル リクエストを使用したデプロイ  ステップを手動実行する ドキュメント: bitbucket-pipelines.yml の設定 - アトラシアン製品ドキュメント\n trigger: manual をつける。 ※最初のステップは手動にはできない  Example:\npipelines:default:- step:script:- ./run-test.sh- step:trigger:manualscript:- ./deploy.shTips:\n パイプライン全体を手動トリガーで実行する場合、customパイプラインを使う  Dockerイメージの利用 Docker イメージをビルド環境として使用する - アトラシアン製品ドキュメント\n DockerHubでは認証情報を渡すことでプライベートイメージの利用も可能 AWSのECRやGCPのGCRも利用可能  パイプラインの変数 パイプラインでの変数 - アトラシアン製品ドキュメント\n 「secure」チェックをONにすると、パイプラインの実行ログ上でもマスクされ、表示されなくなる  $MY_SECRET のように表示される    パイプラインをトリガーせずにコミット コミットメッセージに [skip ci] または [ci skip] を含める。\nBitbucket Pipelines の FAQ - アトラシアン製品ドキュメント\n","excerpt":"Atlassian社が提供しているソースコードのホスティングサービス。\nJIRAなど他のAtlassian製品との連携が強み（だと思う）。\n提供形態  クラウド \u0026hellip; Bitbucket …","ref":"/tech-notes/a/web-service/bitbucket/","title":"Bitbucket"},{"body":"設定ファイルの記法等。\nv0.12以降に対応。\nv0.11以前は子ページを見よ。\n基本文法  https://www.terraform.io/docs/configuration/syntax.html  文字列  $ をそのまま文字列内で扱いたいときは \u0026quot;$$\u0026quot; とエスケープする。  変数管理 Variables https://www.terraform.io/docs/configuration/variables.html\nterraformで使用する変数は .tf ファイル内に variable ブロックで定義する。\n定義ブロック内で default 値を設定することもできるが、以下のいくつかの方法で値を注入できる。\n .tfvars ファイルに HCL or JSON で記述し、terraform実行時に -var-file \u0026lt;FILE\u0026gt; という引数で渡す  カレントディレクトリ直下の terraform.tfvars ファイルまたはsuffixが .auto.tfvars のファイルは自動的に読み込まれる。   terraform実行時に -var 'key=value' という引数で渡す 環境変数 TF_VAR_keyname を設定すると keyname 変数がセットされる  参考:\n Terraform で変数を使う - Qiita  Local Values https://www.terraform.io/docs/configuration/locals.html\nmodule内などのスコープで使える変数を定義する。\nvariableで定義した変数を参照したり、演算結果を使ったり出来るので便利。\n参考:\n 【モダンTerraform】VariableとLocal Valuesの使い分けについて - febc技術メモ  Expressions(v0.12〜) https://www.terraform.io/docs/configuration/expressions.html\nSplat https://www.terraform.io/docs/configuration/expressions.html#splat-expressions\n[*] によるリストの展開\nExamples\n# 1 var.list[*].id## for式による↑と等価な構文 [for o in var.list : o.id]# 2 var.list[*].interfaces[0].name## for式による↑と等価な構文 [for o in var.list : o.interfaces[0].name] Dynamic blocks https://www.terraform.io/docs/configuration/expressions.html#dynamic-blocks\nresource内のブロックの繰り返し記述をDRYに書けるようになった。\nExample:\nresource \u0026#34;aws_elastic_beanstalk_environment\u0026#34; \u0026#34;tfenvtest\u0026#34; { name = \u0026#34;tf-test-name\u0026#34; application = \u0026#34;${aws_elastic_beanstalk_application.tftest.name}\u0026#34; solution_stack_name = \u0026#34;64bit Amazon Linux 2018.03 v2.11.4 running Go 1.12.6\u0026#34; dynamic \u0026#34;setting\u0026#34; { for_each = var.settings content { namespace = setting.value[\u0026#34;namespace\u0026#34;] name = setting.value[\u0026#34;name\u0026#34;] value = setting.value[\u0026#34;value\u0026#34;] } } } ※あまり使いすぎない方がいいと書いてある。\nFunctions(v0.12〜) https://www.terraform.io/docs/configuration/functions.html\nv0.11以前は Interpolation Syntax だったもの。\nCollection concat https://www.terraform.io/docs/configuration/functions/concat.html\nlistの結合\nExamples:\n\u0026gt; concat([\u0026#34;a\u0026#34;, \u0026#34;\u0026#34;], [\u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]) [ \u0026#34;a\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, ] Encoding jsondecode https://www.terraform.io/docs/configuration/functions/jsondecode.html\nJSONをデコードしてobject(map), tuple(list), stringなどを作る。\n逆の操作をする関数は jsonencode\nExamples:\n\u0026gt; jsondecode(\u0026#34;{\\\u0026#34;hello\\\u0026#34;: \\\u0026#34;world\\\u0026#34;}\u0026#34;) { \u0026#34;hello\u0026#34; = \u0026#34;world\u0026#34; } \u0026gt; jsondecode(\u0026#34;true\u0026#34;) true メタパラメータ https://www.terraform.io/docs/configuration/resources.html#meta-parameters\n全てのresourceで使えるパラメータ。\n count (int) \u0026hellip; リソースを作成する件数。 depends_on (list of strings) \u0026hellip; リソースやmoduleの依存関係を指定する。 lifecycle (block)  lifecycle このブロックは以下のキーを取る:\n create_before_destroy (bool) \u0026hellip; リソースを作り直すときに、元のを削除する前に 新しいリソースを作っておく。 prevent_destroy (bool) \u0026hellip; リソースの削除を防ぐ ignore_changes (list of strings) \u0026hellip; リソースの特定のパラメータの変化を無視する  例えば、AWS AutoScalinGroupで下のように設定しておくと、スケールアウトしたときにterraformを適用してもインスタンス数をリセットして事故になることを防ぐことができる。    resource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;my_cluster\u0026#34; { min_size = 1 max_size = 10 desired_capacity = 1 lifecycle { ignore_changes = [\u0026#34;desired_capacity\u0026#34;] } } 参考:\n Terraform職人入門: 日々の運用で学んだ知見を淡々とまとめる - Qiita#リソースの差分を無視する  Workspaces https://www.terraform.io/docs/state/workspaces.html\n.tf ファイル内で ${terraform.workspace} でworkspace名を参照できる。\nExample:\nresource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { count =\u0026#34;${terraform.workspace == \u0026#34;default\u0026#34; ? 5 : 1}\u0026#34;# ... other arguments } 参考:\n はじめてのTerraform 0.12 ～実践編～ | Future Tech Blog - フューチャーアーキテクト  Terraform https://www.terraform.io/docs/configuration/terraform.html\nTerraformの設定。\nExample:\nterraform { backend \u0026#34;s3\u0026#34; { : } required_version \u0026gt;= \u0026#34;0.12.0\u0026#34; } Backends https://www.terraform.io/docs/backends/\n S3 GCS  Partial Configuration https://www.terraform.io/docs/backends/config.html#partial-configuration\n一部の設定を .tf ファイルではなくコマンドラインや外部ファイルで渡す方式。\nModule レシピを module という単位にまとめて再利用性を高めることができる。\n https://www.terraform.io/docs/modules/usage.html https://www.terraform.io/docs/configuration/modules.html  Tips:\n module内では ${module.path} によってmoduleのルートパスを取得できる  相対パス . などでは上手く行かないケースがありそう    参考:\n terraform module内でtemplatefile関数を実行した際に、ファイルが見つけられなくて困った - Qiita  Data Source データを既存インフラや他のTerraform被管理物から取ってくる。\n https://www.terraform.io/docs/configuration/data-sources.html  Output moduleの属性値を他のmoduleで利用できるようにしたり、remote stateとして他の環境から参照可能にしたりする。\nhttps://www.terraform.io/docs/configuration/outputs.html\nChild Pages ","excerpt":"設定ファイルの記法等。\nv0.12以降に対応。\nv0.11以前は子ページを見よ。 …","ref":"/tech-notes/a/software/terraform/config/","title":"Configuration"},{"body":"","excerpt":"","ref":"/tech-notes/a/memo/","title":"Memorandum"},{"body":"障害情報  https://status.cloud.google.com/  RSSもある   https://twitter.com/gcpstatus でも配信されている  quota リソース制限。割当て上限。\n緩和方法 参考:\n GCP リソースの割り当てを増加(上限緩和申請) - Qiita  コスト管理 コスト節約のためのナレッジ:\n 2020-04-21 クラウドコストの最適化のためのベスト プラクティス | Google Cloud Blog  監査 Cloud Audit Logging https://cloud.google.com/logging/docs/audit/?hl=ja\nデフォルトでもある程度ログを取ってくれるが、有効期限がある。\n永久に保存したい場合は、GCSにエクスポートが必要そう。\nhttps://cloud.google.com/logging/quotas?hl=ja#logs_retention_periods\n組織 AWSのOrganizationみたいなものと思う。\nG Suiteだとドメインに紐づくか。\nフォルダ フォルダを作って組織内のプロジェクトを階層化できる。\n例えば組織の部門ごとにフォルダを作ると、権限管理など便利。\nSee フォルダの作成と管理 | Google Cloud Resource Manager ドキュメント | Google Cloud\nプロジェクトを組織に移行 元々組織に紐付いていなかったプロジェクトを組織に紐付けることができる。\n戻すこともできるが、プロジェクト作成者のみ(？)\nプロジェクトは組織のポリシーに準じるようになるので、不整合が起こらないようにしないといけない、といった注意点があるようだ。\nSee 組織に既存のプロジェクトを移行する | Google Cloud Resource Manager ドキュメント | Google Cloud\n制限 組織内に作れるプロジェクト数は上限がある。\n緩和申請もできるみたい。\n Project quota requests - Cloud Platform Console ヘルプ  構成管理 Cloud Deployment Manager https://cloud.google.com/deployment-manager/\nYAMLでPythonテンプレートとJinja2に対応している。\n Documentation: https://cloud.google.com/deployment-manager/docs/  サポートされるリソースタイプ | Cloud Deployment Manager のドキュメント | Google Cloud    開発 ローカル開発用サーバ 一部のサービスには、自動テストなどでも使えるエミュレータが提供されている:\n Cloud Datastore Cloud Bigtable Cloud Pub/Sub  Service Usage https://cloud.google.com/service-usage/docs/overview?hl=ja\nGCPサービスやAPIの表示、管理。\n権限 https://cloud.google.com/service-usage/docs/access-control\nQuotaやBillingの操作をするとき、 serviceusage.services.use が要求される。\n例:\n gcloud logging logs list  Tips ラベルの運用 ラベルの作成と管理 | Resource Manager のドキュメント | Google Cloud\n参考  はじめてのGCP - Qiita \u0026hellip; 2018年8月時点だが、ネットワークセキュリティ周りなどそこそこまとまっている  Child Pages ","excerpt":"障害情報  https://status.cloud.google.com/  RSSもある   https://twitter.com/gcpstatus でも配信されている  quota リソース …","ref":"/tech-notes/a/gcp/","title":"Google Cloud Platform"},{"body":"gitコマンド 参考資料  【Git】基本コマンド - Qiita  apply ## git diffコマンドで作ったpatchを適用する git apply file.patch 参考:\n Git でパッチファイルを作成する | まくまくGitノート  archive NOTE:\n tar を使わないとファイルに実行ビットがついてしまうようだ。  参考:\n Git リポジトリの内容を zip ファイルにする - Qiita  branch https://git-scm.com/docs/git-branch\n# ローカルのbranchを表示 git branch # 今のbranchを元に新しいbranchを作る git branch \u0026lt;newbranch\u0026gt; # 既存のbranchを元に新しいbranchを作る git branch \u0026lt;oldbranch\u0026gt; \u0026lt;newbranch\u0026gt; checkout ## topicブランチを作成 git checkout -b topic ## remoteブランチからローカルブランチを作成 git checkout -b foo origin/foo ## 空ブランチを作る git checkout --orphan empty 参考:\n gitの空ブランチを作る - Qiita  cherry-pick 別ブランチで開発中の機能などをコミット単位で取り込むときに使う。\ngit cherry-pick \u0026lt;SHA1\u0026gt; ## マージコミットのcherry-pick git cherry-pick -m 1 \u0026lt;SHA1\u0026gt; 参考:\n merge commitをcherry-pickする - Qiita  clone https://git-scm.com/docs/git-clone\n## 深さ1の shallow clone git clone --depth 1 \u0026lt;URL\u0026gt; ## ブランチ指定 git clone --branch BRANCH URL commit ## 変更点を表示してコミット git commit -v ## 空コミット git commit --allow-empty ## コミットメッセージを変更 git commit --amend diff ## スペース等の差分を無視 git diff -w ## ファイル名のみ表示 git diff --name-only fetch ## remote で削除された branch について、local のトラッキングブランチも消す git fetch -p|--prune log ## 過去のコミットから対象文字列を含むコミットを検索 git log -S 文字列 ## 1行で表示 git log --pretty=oneline git log --oneline --graph --decorate ## フォーマット指定 git log --format=\u0026#34;%H\u0026#34; # full commit hash のみ 参考:\n Git - リビジョンの選択 git logのオプションあれこれ - 煙と消えるその前に git log をいい感じに alias して色付きで見やすくしておく - Qiita  rebase ## 過去のNコミットを編集 git rebase -i HEAD~N ## 1st コミットから編集 git rebase -i --root 参考:\n First commit が git rebase -i できない問題 → git rebase -i \u0026ndash;root でできる - 納豆には卵を入れる派です。  remote リモートリポジトリの管理。\n## リモートリポジトリ一覧 git remote git remote -v ## リモートリポジトリ追加 git remote add \u0026lt;リポジトリ名\u0026gt; \u0026lt;URL\u0026gt; ## リモートリポジトリ削除 git remote rm \u0026lt;リポジトリ名\u0026gt; ## URL変更 git remote set-url \u0026lt;リポジトリ名\u0026gt; \u0026lt;URL\u0026gt; ## リポジトリ名変更 git remote rename \u0026lt;リポジトリ名\u0026gt; \u0026lt;新しいリポジトリ名\u0026gt; 参考:\n これで完璧! git remoteでリポジトリを【追加,削除,確認,変更】 | 侍エンジニア塾ブログ（Samurai Blog） - プログラミング入門者向けサイト  revert git revert \u0026lt;SHA1\u0026gt; ## マージコミットの取消し git revert -m 1 \u0026lt;SHA1\u0026gt; 参考:\n https://github.com/git/git/blob/master/Documentation/howto/revert-a-faulty-merge.txt gitのmerge-commitをrevertする - 車輪を再発明 / koba04の日記  submodule https://git-scm.com/docs/git-submodule\nなんだかんだで割りと使っている。\n## 全submodule更新 git submodule foreach git pull origin master sumobuleの削除 =\u0026gt; https://github.com/progrhyme/git-wraps/blob/master/bin/git-submodule-delete\n参考:\n Git submodule の基礎 - Qiita git submoduleしてるリポジトリをリモートの最新に更新する - Qiita  向き先url変更  .gitmodules の向き先を新urlに変更 git submodule sync で反映  .git/config に変更が反映される   git submodule update とかで更新  参考:\n submodule の向き先 url を変更する - Qiita  tag SYNOPSIS:\n## 作成 git tag \u0026lt;タグ名\u0026gt; ### 注釈付き git tag -a \u0026lt;タグ名\u0026gt; -m \u0026lt;メッセージ\u0026gt; ## 表示 git show \u0026lt;タグ名\u0026gt; ### 一覧 git tag ## 削除 git tag -d \u0026lt;タグ名\u0026gt; ## リモートに反映 git push \u0026lt;リモート\u0026gt; \u0026lt;タグ名\u0026gt; git push --tags ### 削除反映 git push \u0026lt;リモート\u0026gt; :\u0026lt;タグ名\u0026gt; 参考:\n 【Git】tag関連コマンド - Qiita  Tips CommitterとAuthorを変更する HEADのcommitを修正する場合:\ngit config --local user.name \u0026#34;YOUR NAME\u0026#34; git config --local user.email your-address@example.com git commit --amend --reset-author 過去の履歴についても変更したい場合:\ngit rebase -i \u0026lt;commit hash\u0026gt; # 該当するコミットを `e` で選ぶ git commit --amend --reset-author git rebase --continue 参考:\n 過去のgitコミットのCommitとAuthor情報を修正する - ひと夏の技術 Git の Commit Author と Commiter を変更する - Qiita  歴史を改ざんする See Git - 歴史の書き換え\n特定のファイル・ディレクトリの履歴を完全に削除 ## file git filter-branch --tree-filter \u0026#39;rm -f path/to/file\u0026#39; HEAD ## directory git filter-branch --tree-filter \u0026#39;rm -rf path/to/dir/\u0026#39; HEAD 参考:\n Git ファイルの履歴を完全に削除する  マージコミットを cherry-pick merge commit を cherry-pick\ngit cherry-pick -m 1 \u0026lt;merge commit のハッシュ\u0026gt; 参考:\n merge commitをcherry-pickする - Qiita  特定のファイルを Git 管理対象から除外する 1) .gitignore や .git/info/exclude を使う 2) 既に Git 管理下にあるファイルをワーキングツリーで敢えて除外する git update-index —assume-unchanged [ファイル名] git update-index —skip-worktree [ファイル名] ## 確認 git ls-files -v ## 取り消し git update-index —no-assume-unchanged [ファイル名] git update-index —no-skip-worktree [ファイル名] git ls-files -v の表示:\n assume-unchanged 設定のファイルは、状態が小文字で表示される skip-worktree 設定のファイルは、状態が S と表示される  参考:\n 既に git 管理しているファイルをあえて無視したい - Qiita  リポジトリをサブディレクトリで分割 サブディレクトリが1つの場合 git clone original_dir new_dir cd new_dir git filter-branch --subdirectory-filter sub_dir_name HEAD 参考:\n gitリポジトリのサブディレクトリを別のリポジトリとして抽出する方法 - 拡張現実ライフ  サブディレクトリが複数の場合 参考:\n git filter branch - Detach many subdirectories into a new, separate Git repository - Stack Overflow  ","excerpt":"gitコマンド 参考資料  【Git】基本コマンド - Qiita  apply ## git diffコマンドで作ったpatchを適用する git apply file.patch 参考:\n Git …","ref":"/tech-notes/a/software/git/","title":"Git"},{"body":"https://www.terraform.io/docs/commands/\nimport https://www.terraform.io/docs/import/usage.html\nterraform import コマンドにより、既存インフラをTerraform管理下に置くことができる。\n一部インフラを手動で作った後、リソースのidを指定して取り込む、といった使い方ができる。\n参考:\n terraform importの使い方メモ - Qiita  plan https://www.terraform.io/docs/commands/plan.html\nExamples:\n# 対象を限定する terraform plan -target=resource_type1.identifier1 -target=resource_type2.identifier2 # planファイルを書き出す terraform plan -out=path/to/tfplan state https://www.terraform.io/docs/commands/state/\nstateの管理・編集を行うコマンド。\nSYNOPSIS:\nterraform state list [filtering-arg] # terraform管理下のリソース一覧 terraform state pull # リモートのstateファイルをダウンロードして標準出力に表示 terraform state push [OPTION] PATH # ローカルのstateファイルをリモートにアップロード terraform state mv SOURCE DESTINATION # リソースの名称変更。module化も可能 terraform state rm リソース # リソースをterraform管理から除く = tfstateファイルから削除 ","excerpt":"https://www.terraform.io/docs/commands/\nimport https://www.terraform.io/docs/import/usage.html …","ref":"/tech-notes/a/software/terraform/cli/","title":"CLI"},{"body":"Documentation https://help.github.com/\n 邦訳: https://help.github.com/ja  Child Pages ","excerpt":"Documentation https://help.github.com/\n 邦訳: https://help.github.com/ja  Child Pages ","ref":"/tech-notes/a/web-service/github/","title":"GitHub"},{"body":"エディタや統合開発環境についても、このセクション下に書くことにする。\nChild Pages ","excerpt":"エディタや統合開発環境についても、このセクション下に書くことにする。\nChild Pages ","ref":"/tech-notes/a/program/","title":"プログラミング"},{"body":"Markdownで管理されたドキュメントからHTML, PDF, ePUBに簡単に製本できるツール。\nただし、2020-04-25現在、クラウドサービスに注力するそうで、OSSのツールチェインは不活発になっていくようだ。\nhttps://github.com/GitbookIO/gitbook\n ⚠️ Deprecation warning\nAs the efforts of the GitBook team are focused on the GitBook.com platform, the CLI is no longer under active development.\nAll content supported by the CLI are mostly supported by our GitBook.com / GitHub integration.\nContent hosted on the legacy.gitbook.com will continue working until further notice. For differences with the new vesion, check out our documentation.\n Documentation  https://docs.gitbook.com/ \u0026hellip; クラウドサービス向け Introduction | GitBook.com Documentation https://github.com/GitbookIO/gitbook/tree/master/docs \u0026hellip; たぶんOSSツールチェインのドキュメントはもうここを読むしかない。  Plugins 目次生成系:\n Package - gitbook-plugin-page-toc zanfab/gitbook-plugin-intopic-toc: GitBook Plugin to add inline table of contents (TOC) to each page using sticky and scrollspy effects. billryan/gitbook-plugin-etoc: Elegant toc plugin for GitBook  参考:\n GitBookによるドキュメント作成 - Qiita  ","excerpt":"Markdownで管理されたドキュメントからHTML, PDF, ePUBに簡単に製本できるツール。\nただし、2020-04-25現在、クラウドサービスに注力するそうで、OSSのツールチェインは不活発 …","ref":"/tech-notes/a/software/gitbook/","title":"GitBook"},{"body":"Go言語製の高速な静的サイトジェネレーター。\nDocumentation https://gohugo.io/documentation/\n Getting Started  Install   Content Management  Front Matter \u0026hellip; ページに対して付けることができるメタデータ   :  Getting Started Install 拡張版のインストール 通常版では、SASS/SCSSサポートがついていないので、必要であれば明示的に拡張版をインストールしないといけない。\nINFO 2020-04-27現在、Macの場合は brew install hugo で拡張版がインストールされるようだ。  参考:\n Themes \u0026gt; Docsy [Hugo]Hugoの通常バージョンとExtendedバージョンとの違い[memo] | 鈍色スイッチ  バイナリをインストール GitHub Releasesから _extended 付きのバイナリを取得する。\nソースからインストール git clone https://github.com/gohugoio/hugo.git cd hugo go install --tags extended Linux Snapの場合:\nsnap install hugo --channel=extended Quickstart # 新しくサイトを作る hugo new site your-new-site # テーマを用意する cd your-new-site git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke echo \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml # コンテンツを作成する hugo new posts/my-first-post.md # hugo serverを起動 hugo server -D ## -D を付けることで draft のページも表示される Configuration Table Of Contents https://gohugo.io/getting-started/configuration-markup/#table-of-contents\n※Goldmarkのみ\n[markup] [markup.tableOfContents] endLevel = 3 ordered = false startLevel = 2 Known Issues 完全なページツリーを描画する機能がない ワークアラウンドでの対応が必要。\nMulti-level sections (tree) · Issue #465 · gohugoio/hugo\nワークアラウンド例:\n http://vjeantet.github.io/hugo-menu-show/  ソースコード    参考:\n サイドバー用のページツリーを表示する（現在表示しているページを考慮した階層表示） | まくまくHugo/Goノート  MEMO:\n Docsyテーマでのサイドバーの実現方法が参考になるかも。  Child Pages ","excerpt":"Go言語製の高速な静的サイトジェネレーター。\nDocumentation https://gohugo.io/documentation/\n Getting Started  Install …","ref":"/tech-notes/a/software/hugo/","title":"Hugo"},{"body":"Getting Started  https://kubernetes.io/docs/home/ \u0026hellip; ドキュメント  https://kubernetes.io/docs/tutorials/ \u0026hellip; チュートリアル https://kubernetes.io/docs/tasks/ \u0026hellip; How-toガイド    Documentation 参考:\n Kubernetes道場 Advent Calendar 2018 - Qiita  Reference  https://kubernetes.io/docs/reference/  APIリファレンス CLIリファレンス etc.    Case Study 参考:\n Kubernetes Failure Stories  Versions  Kubernetes version and version skew support policy - Kubernetes  Features PersistentVolume https://kubernetes.io/docs/concepts/storage/persistent-volumes/\n永続化ボリューム\n参考:\n Kubernetes道場 12日目 - PersistentVolume / PersistentVolumeClaim / StorageClassについて - Toku\u0026rsquo;s Blog  Horizontal Pod Autoscaler  https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/  Podの水平オートスケーラー\n v1 \u0026hellip; CPU使用率(requestsの平均)でスケール v2  https://github.com/kubernetes/community/blob/master/contributors/design-proposals/autoscaling/hpa-v2.md カスタムメトリクス対応 複数メトリクス対応    Example:\nkind:HorizontalPodAutoscalerapiVersion:autoscaling/v2alpha1metadata:name:WebFrontendspec:scaleTargetRef:kind:ReplicationControllername:WebFrontendminReplicas:2maxReplicas:10metrics:- type:Resourceresource:name:cputargetAverageUtilization:80- type:Objectobject:target:kind:Servicename:FrontendmetricName:hits-per-secondtargetValue:1k参考:\n Configuring a Horizontal Pod Autoscaler - GKE GKE クラスタの観察 | Stackdriver Monitoring | Google Cloud GKEでPodとNodeをAutoscaling する - Qiita  Cluster Autoscaler https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler\n FAQ.md  認証/認可 RBAC https://kubernetes.io/docs/reference/access-authn-authz/rbac/\n Role \u0026hellip; 権限ロール。Namespace単位 ClusterRole \u0026hellip; クラスタ全体に効く権限ロール RoleBinding \u0026hellip; Roleとユーザ/グループの紐付け ClusterRoleBinding \u0026hellip; ClusterRoleとユーザ/グループの紐付け  参考:\n Kubernetes道場 20日目 - Role / RoleBinding / ClusterRole / ClusterRoleBindingについて - Toku\u0026rsquo;s Blog KubernetesのRBACについて - Qiita  How-to Podの再起動  K8sはクラスタの状態を宣言型で記述するので、「再起動する」というのを指示するのは難しいようだ 下の記事にあるように、Deploymentの定義を変えてapplyするのが良いだろう レプリカの数を0にして増やすという手もある  See\n 全ての Pod を一発でリロードさせる方法 - Qiita  複数クラスタを設定する  https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/ \u0026hellip; kubectl config use-context で複数クラスタを切り替えられるようにする設定チュートリアル  機密情報や環境設定の扱い SecretsやConfigMapを使う。\n参考:\n Kubernetes 上で Credentials を扱う | tellme.tokyo  Namespaceの削除 https://kubernetes.io/docs/tasks/administer-cluster/namespaces/#deleting-a-namespace\nkubectl delete namespace my-ns kubectl delete -f my-ns.yml 参考:\n Kubernetesでnamespaceを作成・変更・削除する方法 - Qiita [小ネタ]Kubernetesで消せないNamespaceが発生した場合の対処方法 | Developers.IO  Tools Minikube https://github.com/kubernetes/minikube\nローカルでKubernetesを動かすためのツール。\nLinuxのみだが、ハイパーバイザを噛まさず、ローカルのdocker上に直接クラスタを構築することもできる。\n https://kubernetes.io/docs/getting-started-guides/minikube/ \u0026hellip; 導入ガイド  ※先にkubectlをインストールしておくこと    参考:\n minikubeでローカルKubernetesクラスタを5分でつくる方法 - Qiita minikube でローカルでのテスト用 Kubernetes を構築 – 1Q77 ローカルでkubernetesを動かせるminikubeを試す - 年中アイス  Skaffold 開発・本番向けにKubernetesクラスタに継続的デリバリーを実施するコマンドラインツール。\n https://github.com/GoogleContainerTools/skaffold https://skaffold.dev/  Child Pages ","excerpt":"Getting Started  https://kubernetes.io/docs/home/ \u0026hellip; …","ref":"/tech-notes/a/software/k8s/","title":"Kubernetes"},{"body":" A \u0026ldquo;backend\u0026rdquo; in Terraform determines how state is loaded and how an operation such as apply is executed. This abstraction enables non-local file state storage, remote execution, etc.\n Documentation  Configuration Init State Storage \u0026amp; Locking  gcs https://www.terraform.io/docs/backends/types/gcs.html\n 認証用の credentials または access_token が必要。  https://cloud.google.com/sdk/gcloud/reference/auth/application-default/login で作成できるユーザのApplication Default Credentialsでも良い    gcloud auth application-default login s3 https://www.terraform.io/docs/backends/types/s3.html\n ロックしたいときはDynamoDBを使う。  オプション dynamodb_table を指定する    ","excerpt":" A \u0026ldquo;backend\u0026rdquo; in Terraform determines how state is loaded and how an operation such as …","ref":"/tech-notes/a/software/terraform/backend/","title":"Backends"},{"body":"","excerpt":"","ref":"/tech-notes/a/software/","title":"Software"},{"body":"HTTP https://www.terraform.io/docs/providers/http/\nhttp Data Source https://www.terraform.io/docs/providers/http/data_source.html\nSYNOPSIS:\ndata \u0026#34;http\u0026#34; \u0026#34;example\u0026#34; { url = \u0026#34;https://checkpoint-api.hashicorp.com/v1/check/terraform\u0026#34;# Optional request headers request_headers = { \u0026#34;Accept\u0026#34; = \u0026#34;application/json\u0026#34; } } curlで取ってくるようなデータはこれを使えばいい。\n参考:\n TerraformでJSONを扱う方法 - Qiita Getting my own Public IP : Terraform  Local https://www.terraform.io/docs/providers/local/\nローカルのファイルをData Sourceとして読んだり、Resourceとして作成・管理したり。\nData Source https://www.terraform.io/docs/providers/local/d/file.html\ndata \u0026#34;local_file\u0026#34; \u0026#34;foo\u0026#34; { filename = \u0026#34;${path.module}/foo.bar\u0026#34; } Attributes Exported:\n content content_base64  Resource https://www.terraform.io/docs/providers/local/r/file.html\nresource \u0026#34;local_file\u0026#34; \u0026#34;foo\u0026#34; { content = \u0026#34;foo!\u0026#34; filename = \u0026#34;${path.module}/foo.bar\u0026#34; file_permission = \u0026#34;0644\u0026#34; directory_permission = \u0026#34;0755\u0026#34; } Arguments:\n filename 以外はOptional file_permission, directory_permission のデフォルトは \u0026quot;0777\u0026quot;  Random https://www.terraform.io/docs/providers/random/\n乱数値の生成などで使える。\n生成した値はtfstateに保存され、生成時のパラメータが変わらない限り都度、生成することはない。\nResources:\n random_id :  Template https://www.terraform.io/docs/providers/template/\nExample:\n# Template for initial configuration bash script data \u0026#34;template_file\u0026#34; \u0026#34;init\u0026#34; { template = \u0026#34;${file(\u0026#34;init.tpl\u0026#34;)}\u0026#34; vars { consul_address = \u0026#34;${aws_instance.consul.private_ip}\u0026#34; } }# Create a web server resource \u0026#34;aws_instance\u0026#34; \u0026#34;web\u0026#34; {# ...  user_data = \u0026#34;${data.template_file.init.rendered}\u0026#34; } Child Pages（他のProviders） ","excerpt":"HTTP https://www.terraform.io/docs/providers/http/\nhttp Data Source …","ref":"/tech-notes/a/software/terraform/provider/","title":"Providers"},{"body":"","excerpt":"","ref":"/tech-notes/a/web-service/","title":"Webサービス"},{"body":"端末 色  256 Colors - Cheat Sheet - Xterm, HEX, RGB, HSL  ロギング script 参考:\n scriptコマンドで作業ログを記録 ｜ DevelopersIO  Child Pages ","excerpt":"端末 色  256 Colors - Cheat Sheet - Xterm, HEX, RGB, HSL  ロギング script 参考:\n scriptコマンドで作業ログを記録 ｜ …","ref":"/tech-notes/a/cli/","title":"CommandLine Interface"},{"body":"Getting Started  初心者向けガイド: https://www.terraform.io/guides/ ドキュメント: https://www.terraform.io/docs/  参考:\n terraform使い方(超基礎編) - Qiita  仕様 State https://www.terraform.io/docs/state/\nLocking https://www.terraform.io/docs/state/locking.html\nbackendによってサポートされていれば、排他制御が可能。\nExamples 公式のを見ると良い。\n https://github.com/hashicorp/terraform/tree/master/examples  AWS: https://github.com/terraform-providers/terraform-provider-aws/tree/master/examples    ベストプラクティス 公式: https://github.com/hashicorp/best-practices/tree/master/terraform\n   Terraform Version 記事     v0.10 Terraform Best Practices in 2017 - Qiita   v0.7.x Terraformにおけるディレクトリ構造のベストプラクティス ｜ Developers.IO    オレオレ:\n TerraformでWorkspaceを使わずに複数環境をDRYに設定する - Qiita \u0026hellip; Terraform v0.10〜v0.11ぐらい対応  参考:\n Structuring HashiCorp Terraform Configuration for Production \u0026hellip; 2020-03-27. Workspacesを使わずにディレクトリを分けることのメリットが述べられている。  How-to バージョン固定 Terraform Settings - Configuration Language - Terraform by HashiCorp\nExamples:\nterraform { required_version =\u0026#34;\u0026gt;= 0.12\u0026#34; required_providers { aws =\u0026#34;\u0026gt;= 2.8\u0026#34; local = \u0026#34;1.2\u0026#34; } } provider \u0026#34;http\u0026#34; { version = \u0026#34;1.2.0\u0026#34; }  terraformのversion指定はtfenvでも可能  参考:\n tfupdateでTerraform本体/プロバイダ/モジュールのバージョンアップを自動化する - Qiita  BackendのS3やGCS等そのものをTerraformで管理 参考:\n Backend の S3 や DynamoDB 自体を terraform で管理するセットアップ方法 - Qiita  Tips デバッグ https://www.terraform.io/docs/internals/debugging.html\nログレベルの変更 TF_LOG 環境変数に TRACE, DEBUG, INFO, WARN, ERROR のいずれかをセットすることで変更できる。\nTF_LOG=DEBUG terraform plan ※しかし、どれを指定してもtraceレベルのログが出る気が…(v0.10.x)\ncountを使って複数のリソースを作成 Examples:\nvariable \u0026#34;instance_ips\u0026#34; { default = { \u0026#34;0\u0026#34; = \u0026#34;10.11.12.100\u0026#34; \u0026#34;1\u0026#34; = \u0026#34;10.11.12.101\u0026#34; \u0026#34;2\u0026#34; = \u0026#34;10.11.12.102\u0026#34; } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;app\u0026#34; { count = \u0026#34;3\u0026#34; private_ip = \u0026#34;${lookup(var.instance_ips, count.index)}\u0026#34;# ... } variable \u0026#34;rds_roles\u0026#34; { default = [\u0026#34;WRITER\u0026#34;, \u0026#34;READER\u0026#34;] } resource \u0026#34;aws_cloudwatch_metric_alarm\u0026#34; \u0026#34;rds_cpu\u0026#34; { count = \u0026#34;2\u0026#34; alarm_name = \u0026#34;RDS-${var.rds_roles[count.index]}-CPU\u0026#34; : } 参考:\n https://www.terraform.io/docs/configuration/resources.html#using-variables-with-count terraformでautoscalingしているサーバのcloudwatch alarmを自動設定する - Qiita Terraform でループして複数のリソースを作成する - Qiita  変数やoutputでmapを使うと記述量が減って便利 参考:\n Terraformのoutputでmapを利用する方法 - Qiita  mapのlistを作る方法  A hacky way to create a dynamic list of maps in Terraform  できない説  Cannot pass a list of maps to a resource/data · Issue #7705 · hashicorp/terraform Terraform でループして複数のリソースを作成する - Qiita  …が、手元で試したところ(v0.10.x)、下のようにしてlistとして定義・参照することができた。\nvariable \u0026#34;my_complex_data\u0026#34; { type = \u0026#34;list\u0026#34; default = [ { id = \u0026#34;1\u0026#34; name = \u0026#34;taro\u0026#34; height = \u0026#34;170\u0026#34; }, { id = \u0026#34;2\u0026#34; name = \u0026#34;hanako\u0026#34; height = \u0026#34;160\u0026#34; }, ] } foo_list = \u0026#34;${var.my_complex_data}\u0026#34; Tools 3rd Partyのツール\ntfenv https://github.com/Zordrak/tfenv\nrbenv, anyenvのようなツールで、複数バージョンのterraformを切り替えて使えるようになるもの。\n参考:\n tfenvでTerraformのバージョン管理をする - Qiita  参考  Terraform職人入門: 日々の運用で学んだ知見を淡々とまとめる - Qiita  ","excerpt":"Getting Started  初心者向けガイド: https://www.terraform.io/guides/ ドキュメント: https://www.terraform.io/docs/   …","ref":"/tech-notes/a/software/terraform/","title":"Terraform"},{"body":"筆者はLinuxかmacOSを使うことが多い。\nAbout 参考:\n List of Unix commands - Wikipedia \u0026hellip; IEEE規格らしい。  日付・時刻・時間 date ## 書式指定 date +%Y%m%d # YYYYMMDD date +%FT%T # ISO8601風 date +%s # unixtime ## 日時指定/相対 date -d tomorrow # 明日 date -d \u0026#39;1 hour\u0026#39; # 1時間後 date -d \u0026#39;1 days ago\u0026#39; # 昨日 ## 日時指定/絶対 date -d @1530675922 # unixtime NOTE:\n Mac だと -d '〜' オプションが使えない  参考:\n 日付を取得する | UNIX \u0026amp; Linux コマンド・シェルスクリプト リファレンス date コマンド | コマンドの使い方(Linux) | hydroculのメモ  ファイル操作 tee 標準出力に書きつつファイルにも書く、ということをやりたいときに使う。\n./a.sh | tee a.log ./a.sh | tee -a a.log # 追記 ./a.sh 2\u0026gt;\u0026amp;1 | tee a.log # 標準エラーもファイルに書く 参考:\n teeコマンドの使い方 - Qiita  touch touch -t 201807040100 path/to/file # mtimeを2018/7/4 01:00に変更 参考:\n 【 touch 】コマンド――タイムスタンプを変更する／新規ファイルを作成する：Linux基本コマンドTips（23） - ＠IT  アーカイブ zip/unzip ## dir/ を再帰的に圧縮 ## 展開すると dir/ も出来る zip -r foo.zip dir/ ## 中身を bar/ に展開 unzip foo.zip -d bar/ 参考:\n Linuxコマンド集 - 【 zip 】 ファイルを圧縮する（拡張子.zip）：ITpro Linux基本コマンドTips（35）：unzipコマンド――ZIPファイルからファイルを取り出す - ＠IT  テキスト処理 grep ## ファイル名だけ表示 grep -l PATTERN [PATH] head https://linuxjm.osdn.jp/html/GNU_textutils/man1/head.1.html\n## 先頭1行を表示 head -1 [file...] ## 先頭20行を表示 head -n 20 [file...] ## 先頭256Bを表示 head -c 256 [file...] ## 先頭256KBを表示 head --bytes 256k [file...] sort ## 第2フィールドで数値の降順ソート cat file | sort -nr -k2 参考:\n https://linuxjm.osdn.jp/html/gnumaniak/man1/sort.1.html sort コマンド | コマンドの使い方(Linux) | hydroculのメモ  ファイルシステム exportfs exportfs -a # /etc/exports の全てのディレクトリをエクスポート exportfs -v # 現在エクスポート中のディレクトリ一覧 参考:\n exportfs コマンド  mount ## uid, gid指定 mount -o uid=1000,gid=1000 /dev/sdb1 /mnt ※NFSの場合、uid/gid指定は不可\nSee also:\n https://sites.google.com/site/progrhymetechwiki/linux/fs  参考:\n 【 mount 】コマンド――ファイルシステムをマウントする：Linux基本コマンドTips（183） - ＠IT 製品レビュー：企業ユーザーのためのSFU 3.5活用ガイダンス　第1回　SFU 3.5の概要とNFS機能　2．NFSとユーザー名マッピング - ＠IT  umount umount \u0026lt;mount先\u0026gt; umount \u0026lt;mount元\u0026gt; ユーザ管理 getent getent group \u0026lt;group\u0026gt; # グループに属しているユーザをリスト 参考:\n Linuxコマンドでユーザーのグループ確認・変更。 - Qiita  gpasswd gpasswd -a \u0026lt;login\u0026gt; \u0026lt;group\u0026gt; # ユーザをグループに所属させる gpasswd -d \u0026lt;login\u0026gt; \u0026lt;group\u0026gt; # ユーザをグループから削除 参考:\n 【 gpasswd 】コマンド――ユーザーが所属するグループを管理する：Linux基本コマンドTips（72） - ＠IT  groupadd グループ作成。\ngroupadd newgroup 参考:\n Linuxコマンド【 groupadd 】新規グループの作成 - Linux入門 - Webkaru  passwd passwd -l \u0026lt;login\u0026gt; # アカウントをロック passwd -u \u0026lt;login\u0026gt; # アンロック ロックされたアカウントはログインできず、利用不可になる。\n参考:\n Linux ユーザーアカウントをロック・アンロックする  useradd ユーザ追加。オプション多数\n   オプション 意味     -m ホームディレクトリ作成   -s \u0026lt;SHELL\u0026gt; ログインシェルを指定    Examples:\n## ホームディレクトリ作成 useradd -m \u0026lt;login\u0026gt; ## ログインシェルを/bin/bashに useradd -s /bin/bash \u0026lt;login\u0026gt; 参考:\n useraddコマンドについて詳しくまとめました 【Linuxコマンド集】  usermod usermod -g admin \u0026lt;login\u0026gt; # 主グループを変更 usermod -aG ops,app,... \u0026lt;login\u0026gt; # 副グループ追加 参考:\n usermodコマンドについて詳しくまとめました 【Linuxコマンド集】  リソース管理 ps Man page of PS\nExamples:\nps aux ps aufxwww ps auxwww -L ps -ef ps -efL Options:\n   option 意味     f forest, プロセスをツリー状に表示   -L スレッド表示。 f と同時に指定はできない    top(1) top(1): tasks - Linux man page\nExamples:\n# インタラクティブモード top ## 描画間隔を5秒に変更 top -d 5 # バッチモードで1回だけ実行 top -b -n 1 ## CPUコアごとの負荷も表示 top -b -n 1 -1 インタラクティブモードの主な操作:\n M \u0026hellip; メモリ使用率順にソート P \u0026hellip; CPU使用率順にソート 1 \u0026hellip; CPUコアごとの負荷を表示 c \u0026hellip; プロセス名詳細を表示（トグル） q \u0026hellip; 終了 F or O \u0026hellip; ソートするフィールドを選ぶ R \u0026hellip; ソートの昇順/降順を切り替え  Mac版の違い:\n -b オプションやバッチモードがなさそう CPUコアごとに負荷を見る方法がわからん  参考:\n [Linux] top コマンドをインタラクティブに操作する | バシャログ。  ユーティリティー watch watch -n \u0026lt;N\u0026gt; command args... N秒ごとにコマンドを実行して出力を表示。\n参考:\n watch コマンド | コマンドの使い方(Linux) | hydroculのメモ  ","excerpt":"筆者はLinuxかmacOSを使うことが多い。\nAbout 参考:\n List of Unix commands - Wikipedia \u0026hellip; IEEE規格らしい。  日付・時刻・ …","ref":"/tech-notes/a/cli/unix-cmd/","title":"UNIX系コマンド"},{"body":"Commands Basic \u0026#34; 全行削除%d参考:\n vim - 全行削除コマンド - IT Notebook  Advanced Usage \u0026#34; ファイル全体をインデントgg=G参考:\n cl.pocari.org - Vim でインデントを整える  Specs 検索  ノーマルモードで / を打って検索。 /\\c で始めると大文字小文字を区別せずに検索  参考:\n Vim内で検索するときに大文字小文字を気にしない（ignore case）する方法 - Qiita  正規表現 参考:\n vim正規表現リファレンス - Qiita  Topics オプションのグローバルな値とローカルな値 Vim: オプションのグローバルな値とローカルな値 - while (“im automaton”); より。\n ふつうは set を使う ローカルに設定したい値は setlocal を使う。そうでないとグローバル値も変化してしまう  例えば ftplugin/xxx でファイルタイプごとの設定をするときに set を使ってしまうと、ファイルを開くたびにグローバルの設定値が変化しかねない    How-to 改行文字の置換（挿入/削除） ; 改行を削除:s/\\n//g; 改行を挿入:s//\\r/gSee vimの置換で改行を(挿入|削除)する - Qiita\n","excerpt":"Commands Basic \u0026#34; 全行削除%d参考:\n vim - 全行削除コマンド - IT Notebook  Advanced Usage \u0026#34; ファイル全体をインデントgg=G参 …","ref":"/tech-notes/a/program/vim/","title":"Vim"},{"body":"http://www.zsh.org/\nSource Code  https://sourceforge.net/p/zsh/code/ci/master/tree/ https://github.com/zsh-users/zsh \u0026hellip; Mirror  Configuration # history -i でコマンドの実行時間表示 setopt extended_history 参考:\n Unix 系 OS でコマンド実行間にタイムスタンプを付ける  ","excerpt":"http://www.zsh.org/\nSource Code  https://sourceforge.net/p/zsh/code/ci/master/tree/ …","ref":"/tech-notes/a/cli/zsh/","title":"Zsh"},{"body":"UNIX系OS UNIX風の仕様や操作感、振る舞いのOS。\nUNIX系OS（UNIX-like OS）とは - IT用語辞典 e-Wordsによれば、\n 現在、「UNIX」の商標権は米業界団体The Open Group（オープングループ）が所有している。同団体の定めた「Single UNIX Specification」という仕様を満たし、認証を受けて商標利用のライセンス料を支払った製品のみが公式にUNIX互換であると名乗ることができる。\n とのことであり、これらにはSolaris, HP-UX, AIXなどのいわゆる商用UNIXと呼ばれるOS製品が該当するそうだ。\nその他、一般にUNIX系OSと呼ばれるもの:\n Linux BSD系  FreeBSD, OpenBSD, NetBSD macOS    UNIX UNIX（ユニックス）とは - IT用語辞典 e-Wordsより:\n 1969年にAT\u0026amp;T社ベル研究所で開発が始まったオペレーティングシステム（OS）。また、その流れを汲むOSの総称。\n  広義には、正規のUNIXシステムとUNIX系OSすべてを含む総称としてUNIXという語を用いることもある。\n ","excerpt":"UNIX系OS UNIX風の仕様や操作感、振る舞いのOS。\nUNIX系OS（UNIX-like OS）とは - IT用語辞典 e-Wordsによれば、\n 現在、「UNIX」の商標権は米業界団体The …","ref":"/tech-notes/a/os/","title":"オペレーティングシステム"},{"body":"Micfosoftが提供するOSSのクロスプラットフォームなコードエディタ。\nElectronをベースにしており、IDE並の機能を持つ。\n3rd Partyの拡張機能も多数あり、機能を拡充することができる。\nDocumentation  https://code.visualstudio.com/docs  Get Started:  Visual Studio Code Key Bindings   User Guide:  Managing Extensions in Visual Studio Code      Features スニペット機能  ユーザ定義のスニペットを作成可能  File \u0026gt; Preferences \u0026gt; User Snippets コメント付きJSON形式で書く グローバルなスニペット ワークスペースごとのスニペット   スニペットが有効になると、補完で選択可能になる  参考:\n 独自のスニペットを作成 | 非公式 - Visual Studio Code Docs VS Codeをスニペット作成は簡単で便利だった！ - lisz-works  Preferences 昔はJSON設定ファイルを直接編集するようなスタイルだったが、2018年9月現在、GUIで設定できる項目も増えてきたようだ。\n2種類の設定がある。\n ユーザ設定 \u0026hellip; ワークスペースによらない、ユーザ環境で常に有効になる設定。 ワークスペース設定 \u0026hellip; ワークスペースの .vscode/settings.json に保存される。  Quick Reference:\n   config 値（*） 意味     editor.insertSpaces true, false ソフトタブ（タブキーで半角スペースを挿入）のon/off   editor.renderWhitespace none, all, boundary スペースやタブを描画するかどうか。 boundary では単語境界は描画しない    （*）デフォルト値は太字\n参考:\n VSCodeのエディター設定の話 - タブ文字がなぜか半角スペースになってしまう - Qiita  言語ごとの設定を行う インデントなどの設定を言語ごとに変えることができる。\nsettings.jsonで \u0026quot;[ruby]\u0026quot;: {} などのエントリを作って、その中に設定を記述すればいい。\nコマンドパレットで Preferences: Configure language specific settings と入力し、設定したい言語を選ぶやり方もある。\n参考:\n vscode - Visual Studio Codeで言語ごとにインデントの設定をしたい - スタック・オーバーフロー  インデント設定    config 値（*） 意味     editor.detectIndentation true, false ファイルタイプごとのインデント設定を有効にする   editor.insertSpaces true, false ソフトタブ（タブキーで半角スペースを挿入）のon/off   editor.tabSize 4 インデント幅    （*）デフォルト値は太字\nなぜか設定が反映されないときや、一時的に設定を変更したいときは、画面右下のインデント設定をクリックすることでアドホックに変更が可能。\n参考:\n VS Codeでインデントを設定するには：Visual Studio Code TIPS - ＠IT 【Visual Studio Code】インデント幅の変更方法と、変えても反映されない時の対処法 vscode - Visual Studio Codeで言語ごとにインデントの設定をしたい - スタック・オーバーフロー  フォント設定    config 値（*） 意味     editor.fontSize  エディタのフォントサイズ    （*）デフォルト値は太字\n参考:\n Visual Studio Codeでフォントサイズをいい感じにする - Qiita  ファイルを常に新しいタブで開く workbench.editor.enablePreview: false に設定し、プレビューを無効化する。\n参考:\n [Visual-Studio-Code] ファイルを常に新しいタブで開くようにvscodeを設定するには？ | CODE Q\u0026amp;A 問題解決 [日本語]  テキストの折り返し デフォルトは editor.wordWrap が折り返さない設定(= off)になっている。\nその他、次のオプションが有る:\n on \u0026hellip; エディタの右端で折り返す wordWrapColumn \u0026hellip; editor.wordWrapColumn で設定した値で折り返す bounded \u0026hellip; editor.wordWrapColumn 設定値とエディタの幅の小さい方で折り返す  参考:\n VS Codeでテキストの折り返しを設定するには：Visual Studio Code TIPS - ＠IT  ショートカットキー    Win/Linux Mac 機能     Ctrl+, ⌘+, 設定画面を開く   Ctrl+Shift+p  コマンドパレットを開く   Ctrl+Shift+x  拡張機能を開く   Ctrl+Shift+@ ⌘+Shift+@ ターミナルを開く   Ctrl+k v ⌘+k v Markdownファイルのプレビュー画面をサイドバイサイドで表示   Ctrl+Shift+v ⌘+Shift+v Markdownファイルのプレビュー画面を別タブで表示   Ctrl+k Ctrl+s ⌘+k ⌘+s キーバインド一覧を開く   Ctrl+k Ctrl+t ⌘+k ⌘+t カラーテーマ(配色)設定    参考:\n Visual Studio Code キーボード ショートカット - Qiita VS CodeでMarkdownをプレビューするには？：Visual Studio Code TIPS - ＠IT  キーバインドの変更 ↑のキーバインド一覧から変更可能\nExtensions 改行コードの表示  code-eol  設定値: code-eol.color \u0026hellip; 改行を表す記号の文字色を16進数のカラーコードで指定。  例: \u0026quot;#841a75\u0026quot; (ラズベリー色)     line-endings  2018年9月、code-eolを入れて使っている。\ntextlint  vscode-textlint  日本語の書き方など指摘・修正してくれるLintツール。\n使い方:\n VS Codeでtextlintを使って文章をチェックする - Qiita  How-to VS Codeの更新 Ubuntu:\n debパッケージをダウンロード sudo dpkg -i code_xxx.deb  ","excerpt":"Micfosoftが提供するOSSのクロスプラットフォームなコードエディタ。\nElectronをベースにしており、IDE並の機能を持つ。\n3rd Partyの拡張機能も多数あり、機能を拡充することがで …","ref":"/tech-notes/a/program/vscode/","title":"Visual Studio Code"},{"body":"5/2 Bitbucket PipelinesでGCPに対してTerraformを適用するには 必要なもの:\n 必要な権限が付与されたService Account Key GCPで必要なAPIを有効化  操作対象のリソースによって異なる。以下は例:  Cloud Resource Manager API \u0026hellip; Service Accountの作成に必要だった Compute Engine API \u0026hellip; GCEインスタンス作成などで必要そう      手順:\n Service Account Keyを作り、JSON形式で取得   をBitbucketのリポジトリ変数にsecure変数として設定。キーはなんでもいいが、ここでは GOOGLE_CREDENTIALS_DATA とする。Base64化は不要   下のような bitbucket-pipelines.yml を用意する  image:hashicorp/terraform:0.12.24definitions:steps:- step:\u0026amp;terraform-planname:terraformplanscript:- echo\u0026#34;${GOOGLE_CREDENTIALS_DATA}\u0026#34;\u0026gt;service-account-key.json- exportGOOGLE_APPLICATION_CREDENTIALS=service-account-key.json- terraforminit-input=false- terraformplan-input=false- step:\u0026amp;terraform-applyname:terraformapplyscript:- echo\u0026#34;${GOOGLE_CREDENTIALS_DATA}\u0026#34;\u0026gt;service-account-key.json- exportGOOGLE_APPLICATION_CREDENTIALS=service-account-key.json- terraforminit-input=false- terraformapply-input=false--auto-approvepipelines:branches:\u0026#39;**\u0026#39;:- step:*terraform-planmaster:- step:*terraform-plan- step:\u0026lt;\u0026lt;:*terraform-applytrigger:manual上は、masterを除く任意のbranchに対する更新で terraform plan を実行し、master branchにおいては、 terraform plan を自動実行した後、マニュアルで terraform apply を実行する。\nbranch更新でなく、プルリクエスト駆動にすることもできる。\n上の例で、 pipelines 以下のみ、次のように変更してみる:\npipelines:pull-requests:feature/*:- step:*terraform-planbranches:master:- step:*terraform-plan- step:\u0026lt;\u0026lt;:*terraform-applytrigger:manualこれで、 feature/* にマッチするbranchからのPRにより、 terraform plan が実行される。\nPRした後、branchを更新すればパイプラインが再実行される。\n任意のbranchによるPRを対象にしたい場合は、 feature/* の代わりに '**' と記せば良い。\n参考:\n bitbucket-pipelines.yml の設定 - アトラシアン製品ドキュメント YAML アンカー - アトラシアン製品ドキュメント 2020-05-01に調べたログ Bitbucketについてのメモ  YAMLで配列のマージはできなさそう ハッシュのマージはアンカーとエイリアスでできるのだけど、配列のマージはできなさそう。\n参考: list - How to merge YAML arrays? - Stack Overflow\n配列の1つ1つの要素にアンカーを付けて、再利用することは可能。\n- \u0026amp;markfoo- bar- *mark- *mark#=\u0026gt; [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;foo\u0026#39;]参考: プログラマーのための YAML 入門 (初級編)\nDangerはBitbucketにどのように対応しているか tfnotifyをBitbucketに対応させたいなーと思いながら、参考にできるかなと思って見ていた。\nCIサーバからBitbucketのREST APIを叩いているようだ。\n参考:\n Bitbucket Server by HeEAaD · Pull Request #481 · danger/danger Danger + BitBucket Cloud  ","excerpt":"5/2 Bitbucket PipelinesでGCPに対してTerraformを適用するには 必要なもの:\n 必要な権限が付与されたService Account Key GCPで必要なAPIを有効 …","ref":"/tech-notes/a/memo/20200502/","title":"2020-05-02"},{"body":"Kubernetesクラスタを制御するCLI.\n https://kubernetes.io/docs/reference/kubectl/overview/ リファレンス: https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands kubectl Cheat Sheet - Kubernetes https://kubectl.docs.kubernetes.io/  設定 kubeconfig 環境設定ファイルkubeconfigを参照する順番:\n  --kubeconfig フラグで指定されたパス $KUBECONFIG 環境変数に指定されたパス一覧 ~/.kube/config   See Organizing Cluster Access Using kubeconfig Files - Kubernetes\n参考:\n kubectlの接続設定ファイル（kubeconfig）の概要 - Qiita  環境設定 - config \u0026amp; context ## kubeconfig 表示 kubectl config view ## context ### 一覧表示 kubectl config get-contexts ### 現在のcontext kubectl config current-context ### 変更 kubectl config use-context \u0026lt;context-name\u0026gt; 参考:\n kubectl 用のクラスタ アクセスの構成 | Kubernetes Engine のドキュメント | Google Cloud  実行・公開  run \u0026hellip; コンテナイメージを実行する。deploymentまたはjobが作られる。 expose \u0026hellip; リソースをクラスタ外にServiceとして公開する。  ## run ### 例 kubectl run nginx --image=nginx ## expose ### 例 kubectl expose deployment \u0026lt;deployment-name\u0026gt; --port=80 --target-port=8000 kubectl run \u0026lt;deployment-name\u0026gt; --image=\u0026lt;image-name\u0026gt; --port=\u0026lt;port\u0026gt; kubectl expose deployment \u0026lt;deployment-name\u0026gt; --type=NodePort App Management  autoscale scale \u0026hellip; 次のリソースのサイズを設定する:  Deployment, ReplicaSet, Replication Controller, StatefulSet    ## scale ### ReplicaSet \u0026#39;foo\u0026#39; を3に kubectl scale --replicas=3 rs/foo kubectl scale --replicas=3 -f foo.yml ### 今のサイズが2だったら3にする kubectl scale --current-replicas=2 --replicas=3 deployment/mysql リソース管理 作成・更新  create/apply/replace \u0026hellip; JSON or YAMLのリソース定義ファイルを適用して、リソースを作成/更新する。 patch \u0026hellip; YAML/JSONのマージを用いて、リソース定義を差分更新する  ## create kubectl create -f \u0026lt;Path or URL of config file\u0026gt; ### ファイルから Secret を作成 kubectl create secret generic my-secret --from-file=./secret/secret.json ### ファイルから ConfigMap を作成 kubectl create configmap my-config --from-file=./config/config.json ## apply kubectl apply -f \u0026lt;Path or URL of config file\u0026gt; ### 例 kubectl apply -f https://k8s.io/docs/tasks/run-application/deployment.yaml kubectl apply -f ./pod.json ## replace kubectl replace -f \u0026lt;Path or URL of config file\u0026gt; ## patch kubectl patch \u0026lt;Resource Type\u0026gt; \u0026lt;Name\u0026gt; --patch \u0026lt;YAML Content\u0026gt; ### 例 kubectl patch deployment patch-demo --patch \u0026#34;$(cat patch-file.yaml)\u0026#34; 参考:\n Update API Objects in Place Using kubectl patch - Kubernetes Kubernetes 上で Credentials を扱う | tellme.tokyo Kubernetes道場 23日目 - kubectlを網羅する - Toku\u0026rsquo;s Blog kubectl applyとkubectl replaceの違いは何ですか - コードログ  Pod操作  exec \u0026hellip; コマンドをコンテナ内で実行する cp \u0026hellip; ファイルをクライアント環境とPod間でやりとり  ## exec kubectl exec \u0026lt;pod\u0026gt; -- \u0026lt;command\u0026gt; [args...] ### podにbashでログイン kubectl exec -it \u0026lt;pod\u0026gt; -- /bin/bash -l ## cp kubectl cp path/to/localfile \u0026lt;pod\u0026gt;:/path/to/remotefile kubectl cp \u0026lt;pod\u0026gt;:/path/to/remotefile /path/to/localfile 参考:\n kubernetes: コンテナイメージにログインする - Qiita  Node操作  cordon \u0026hellip; ノードへのスケジュールを停止 drain \u0026hellip; ノードからPodを削除  ## cordon kubectl cordon \u0026lt;node-name\u0026gt; ## drain kubectl drain \u0026lt;node-name\u0026gt; ### DaemonSetで管理されてPodを停止するとき kubectl drain \u0026lt;node-name\u0026gt; --ignore-daemonsets 参考:\n kubernetesの無停止運用を意識した検証 – てっくぼっと！ Kubernetes の drain について検証した時のメモ - Qiita  表示  get \u0026hellip; 単一・複数リソースの情報を表示する。 describe \u0026hellip; 単一リソース or グループの情報を表示 diff \u0026hellip; リソースファイルとクラスタの状態を差分表示  ## get kubectl get deploy[ments] kubectl get po[ds] ### フィルタの例 kubectl get pods -l app=nginx ## describe kubectl describe pods # all pods kubectl describe pod \u0026lt;pod-name\u0026gt; kubectl describe deploy[ment] \u0026lt;deployment-name\u0026gt; ## diff kubectl diff -f foo.yml ### kustomizeバージョン kubectl diff -k . 削除 ## delete kubectl delete deployment \u0026lt;deployment-name\u0026gt; ログ - logs ## 基本構文 kubectl logs \u0026lt;Pod名\u0026gt; [Options] ## 10行 tail -f kubectl logs \u0026lt;Pod名\u0026gt; --tail=10 -f API Proxy kubectl proxy --port=8080 \u0026amp; curl http://localhost:8080/api/ See https://kubernetes.io/docs/tasks/administer-cluster/access-cluster-api/\n","excerpt":"Kubernetesクラスタを制御するCLI.\n https://kubernetes.io/docs/reference/kubectl/overview/ リファレンス: …","ref":"/tech-notes/a/software/k8s/kubectl/","title":"kubectl"},{"body":"5/1 CIでGCPに対してTerraformするには サービスアカウントのキーをJSONで作って、 GOOGLE_CREDENTIALS or GOOGLE_BACKEND_CREDENTIALS 環境変数に渡せば良さそう。 （事例によって異なる環境変数を使っていることがある。）\nhttps://www.terraform.io/docs/backends/types/gcs.html\n（追記） terraform plan のときにはApplication Credentialsが必要になる。\nGCS backend認証も上記の環境変数がない場合は、Application Credentialsにフォールバックするので、環境変数 GOOGLE_APPLICATION_CREDENTIALS にキーファイルのパスを設定するのがよい。\n事例:\n TerraformによるGCP環境の管理 Managing Google Cloud projects with Terraform Terraformツールを使ってGCPリソース管理 | DevSamurai  以前に調べたログ:\n 2020-04-27  tmuxのstatus lineの色設定をいい感じにした 2ヶ月ちょっと前に .tmux.conf をv2.9+対応にしたのだけど、status lineの色設定がなんかイマイチになってたので調整した。\nhttps://github.com/progrhyme/dotfiles/commit/7983437087fdf64aa652f44d922f90a69622353d\nだいぶややこしい設定になっていて、どこを変えればいいかよくわからなくなっていたのと、tmuxプロセスを全て終了しないと再読込みされないっぽかったので更に混乱した。\ntmuxプロセスA内でconfを編集しながら、tmuxプロセスBを起動して見た目を確認していたが、それだとtmuxプロセスAの設定が引き継がれるような挙動だった。\n参考にしたページ:\n tmux の status line の設定方法 - Qiita dotfiles/.tmux.conf at master · tokuhy/dotfiles  TerraformでGCPのService Account Keyを作成 Qiitaにこういうエントリを上げた:\n TerraformでGCPのService Account Keyを作成し、ローカルにファイルとして保存する - Qiita  何度か実行して確かめたところ、次のことがわかった。\n Service Account Keyの内容はtfstateに保存される よって、local_fileに書き出すコードは後で足してもいいし、一度消しても復元できる  ","excerpt":"5/1 CIでGCPに対してTerraformするには サービスアカウントのキーをJSONで作って、 GOOGLE_CREDENTIALS or GOOGLE_BACKEND_CREDENTIALS  …","ref":"/tech-notes/a/memo/20200501/","title":"2020-05-01"},{"body":"4/30 UbuntuでHomebrewで入れたtfenvだとtfenv installに失敗する unzipで失敗する。\nデバッグしたところ、Homebrewの依存でインストールされたunzipが使われてしまうからのようだ。\ntfenvの libexec/helpers 内に which unzip を仕込んで確かめた。\nログ:\n% TFENV_DEBUG=true tfenv install 0.12.24 + [tfenv:22] '[' -z '' ']' ++++ [tfenv:23] readlink_f /home/linuxbrew/.linuxbrew/bin/tfenv : （中略） : + [tfenv-install:180] mkdir -p /home/linuxbrew/.linuxbrew/Cellar/tfenv/1.0.2/versions/0.12.24 + [tfenv-install:181] unzip tfenv_download.DtVL3N/terraform_0.12.24_linux_amd64.zip -d /home/linuxbrew/.linuxbrew/Cellar/tfenv/1.0.2/version s/0.12.24 UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP. Usage: unzip [-Z] [-opts[modifiers]] file[.zip] [list] [-x xlist] [-d exdir] Default action is to extract files in list, except those in xlist, to exdir; file[.zip] may be a wildcard. -Z =\u0026gt; ZipInfo mode (\u0026quot;unzip -Z\u0026quot; for usage). -p extract files to pipe, no messages -l list files (short format) -f freshen existing files, create none -t test compressed archive data -u update files, create if necessary -z display archive comment only -v list verbosely/show version info -T timestamp archive to latest -x exclude files that follow (in xlist) -d extract files into exdir modifiers: -n never overwrite existing files -q quiet mode (-qq =\u0026gt; quieter) -o overwrite files WITHOUT prompting -a auto-convert any text files -j junk paths (do not make directories) -aa treat ALL files as text -C match filenames case-insensitively -L make (some) names lowercase -X restore UID/GID info -V retain VMS version numbers -K keep setuid/setgid/tacky permissions -M pipe through \u0026quot;more\u0026quot; pager See \u0026quot;unzip -hh\u0026quot; or unzip.txt for more help. Examples: unzip data1 -x joe =\u0026gt; extract all files except joe from zipfile data1.zip unzip -p foo | more =\u0026gt; send contents of foo.zip via pipe into program more unzip -fo foo ReadMe =\u0026gt; quietly replace existing ReadMe if archive file newer + [tfenv-install:181] error_and_die 'Tarball unzip failed' ++ [helpers:4] basename /home/linuxbrew/.linuxbrew/Cellar/tfenv/1.0.2/libexec/tfenv-install + [helpers:4] echo -e 'tfenv: tfenv-install: \\033[0;31m[ERROR] Tarball unzip failed\\033[0;39m' tfenv: tfenv-install: [ERROR] Tarball unzip failed + [helpers:5] which unzip /home/linuxbrew/.linuxbrew/bin/unzip + [helpers:6] exit 1 + [helpers:1] rm -rf tfenv_download.DtVL3N  brew uninstall unzip --ignore-dependencies した後、 tfenv install 0.12.24 したら成功した。 /home/linuxbrew/.linuxbrew/bin/unzip some.zip -d somedir は同じエラーで失敗する。 /usr/bin/unzip some.zip -d somedir は成功する。  単独でunzipコマンドを実行しても失敗しているので、Linuxbrewのunzipが壊れてるんだと思う。\n","excerpt":"4/30 UbuntuでHomebrewで入れたtfenvだとtfenv installに失敗する unzipで失敗する。\nデバッグしたところ、Homebrewの依存でインストールされたunzipが使 …","ref":"/tech-notes/a/memo/20200430/","title":"2020-04-30"},{"body":"Cloud SDK https://cloud.google.com/sdk/docs?hl=ja\ngcloud, gsutil, bq CLIもこれに含まれる。\n プロキシ設定  プロキシ / ファイアウォールの背後で Cloud SDK を使用する場合の構成 | Cloud SDK のドキュメント    gcloud  Getting Started: https://cloud.google.com/sdk/gcloud/?hl=ja リファレンス: https://cloud.google.com/sdk/gcloud/reference/?hl=ja  NOTE:\n 新しめの機能の場合、 gcloud beta ... や gcloud alpha ... にしかコマンドがなかったり、 beta ... や alpha ... を付けることで結果が変わることがある  認証 ## 初期設定(認証込) gcloud init ## ログイン認証 gcloud auth login ## 現在認証済みのアカウント一覧 gcloud auth list ## サービスアカウントの認証 gcloud auth activate-service-account --key-file \u0026lt;KEYFILE\u0026gt; ## アクセストークンの表示 gcloud auth print-access-token 参考:\n Cloud SDK ツールの承認 | Cloud SDK のドキュメント | Google Cloud  compute https://cloud.google.com/sdk/gcloud/reference/compute\nExamples:\n## ssh gcloud compute ssh [--project=\u0026lt;PROJECT\u0026gt;] [--zone=\u0026lt;ZONE\u0026gt;] [--internal-ip | --tunnel-through-iap] \\  \u0026lt;INSTANCE\u0026gt; [-- \u0026lt;SSH_ARGS\u0026gt;] ## scp gcloud compute scp [--project=\u0026lt;PROJECT\u0026gt;] [--zone=\u0026lt;ZONE\u0026gt;] [--internal-ip | --tunnel-through-iap] \\  [--recurse] host:/path/to/dir path/to/local ## 証明書 gcloud compute ssl-certificates ### 一覧表示 gcloud compute ssl-certificates list ## イメージの作成 gcloud compute images create my-image --source-disk my-vm-disk instances VM操作\n https://cloud.google.com/sdk/gcloud/reference/compute/instances  create    Examples:\n## 一覧 gcloud compute instances list ## 起動 gcloud compute instances start \u0026lt;INSTANCE\u0026gt; --zone=\u0026lt;ZONE\u0026gt; ## 停止 gcloud compute instances stop \u0026lt;INSTANCE\u0026gt; --zone=\u0026lt;ZONE\u0026gt; ## 作成 gcloud compute instances create my-instance \\  --project=my-project --zone=asia-northeast1-b \\  --no-address \\ # 外部IPなし --custom-vm-type=n1 \\ # N1インスタンス --custom-cpu=4 --custom-memory=8GB \\ # リソースをカスタマイズする場合 --image-project=another-project --image=my-image # 別プロジェクトのイメージを使う 参考:\n イメージとスナップショットの共有 | Compute Engine ドキュメント | Google Cloud  config https://cloud.google.com/sdk/gcloud/reference/config\nSYNOPSIS:\n## 設定値一覧表示 gcloud config list 参考:\n gcloud configで複数の設定を持って切り替える - Qiita  configurations https://cloud.google.com/sdk/gcloud/reference/config/configurations\n設定プロファイルの管理\nSYNOPSIS:\n## プロファイル一覧表示 gcloud config configurations list ## 表示 gcloud config configurations describe プロファイル名 ## 作成 gcloud config configurations create プロファイル名 ## 削除 gcloud config configurations delete プロファイル名 ## 有効化 gcloud config configurations activate プロファイル名 参考:\n SDK 構成の管理 | Cloud SDK のドキュメント | Google Cloud  set https://cloud.google.com/sdk/gcloud/reference/config/set\nExamples:\ngcloud config set project my-project gcloud config set compute/region asia-northeast1 gcloud config set compute/zone asia-northeast1-a functions https://cloud.google.com/sdk/gcloud/reference/functions\nCloud Functionsの操作\ndeploy https://cloud.google.com/sdk/gcloud/reference/functions/deploy\nCloud Functionのデプロイ（作成・更新）\nExample:\n## cloud-buildsイベントをフックに動くFunctionのデプロイ gcloud functions deploy \u0026lt;Function Name\u0026gt; \\  --trigger-topic cloud-builds \\  --runtime nodejs10 \\  --set-env-vars \u0026#34;FOO=foo,BAR=bar\u0026#34; \\  --project my-project logging https://cloud.google.com/sdk/gcloud/reference/logging\nNOTE:\n read, listなどのコマンド利用時には serviceusage.services.use 権限が必要  read https://cloud.google.com/sdk/gcloud/reference/logging/read\nExamples:\ngcloud logging read --format json gcloud logging read --limit=10 --order=asc gcloud logging read \u0026#39;timestamp\u0026gt;=\u0026#34;2020-03-19T05:28:00Z\u0026#34; timestamp\u0026lt;=\u0026#34;2020-03-25T05:33:28Z\u0026#34;\u0026#39; ※2020-04-20現在、 tail -f 相当のオプションはなさそう\nprojects https://cloud.google.com/sdk/gcloud/reference/projects/\nSYNOPSIS:\n## プロジェクト一覧 gcloud projects list 参考  よく使うgcloudコマンドたち - Qiita  gsutil Cloud Storage用のPython製CLI\n ドキュメント: https://cloud.google.com/storage/docs/gsutil コマンドリファレンス: https://cloud.google.com/storage/docs/gsutil/commands/help  mb https://cloud.google.com/storage/docs/gsutil/commands/mb\nバケット作成\nExamples:\ngsutil mb -l asia gs://mybucket ","excerpt":"Cloud SDK https://cloud.google.com/sdk/docs?hl=ja\ngcloud, gsutil, bq CLIもこれに含まれる。\n プロキシ設定  プロキシ / ファ …","ref":"/tech-notes/a/gcp/cli/","title":"CLI"},{"body":"有名なVimのファイラプラグイン。\nUsage ツリービューの操作:\n   キー 用途     ? help表示（トグル）   I 隠しファイルの表示（トグル）    ファイル・ディレクトリを作成 ファイルツリーの任意の位置で m を押すとメニューが表示されるので、 (a)dd a childnode を選ぶ。\nディレクトリを作る場合は末尾に / を入力すること。\nでないと、空のファイルが作られる。\nCtrl-C でメニューを抜けることができた。(Macで)\n","excerpt":"有名なVimのファイラプラグイン。\nUsage ツリービューの操作:\n   キー 用途     ? help表示（トグル）   I 隠しファイルの表示（トグル）    ファイル・ディレクトリを作成 フ …","ref":"/tech-notes/a/program/vim/nerdtree/","title":"NERDTree"},{"body":" 公式リファレンス: https://docs.docker.com/engine/reference/builder/ 邦訳: Dockerfile リファレンス — Docker-docs-ja ドキュメント  ベストプラクティス  https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/  邦訳: http://docs.docker.jp/engine/userguide/eng-image/dockerfile_best-practice.html    参考:\n Introduce that Best practices for writing Dockerfiles \u0026hellip; 2018年12月Japan Container Daysでのモリハヤさんの発表 効率的に安全な Dockerfile を作るには - Qiita  ADDとCOPY http://docs.docker.jp/engine/userguide/eng-image/dockerfile_best-practice.html#add-copy\n COPY で間に合うときは COPY を使うべき ADD は圧縮ファイルの展開などの機能もある  Syntax 環境変数の利用 http://docs.docker.jp/engine/reference/builder.html#environment-replacement\n 全てではないが、一部の命令で環境変数の利用がサポートされている。 ENV 命令で環境変数をセットすることもできる。 コンテナ実行時に環境変数をセットする際は docker run に -e KEY=${VALUE} の形で渡す。  これらを CMD や ENTRYPOINT で解釈する際は、exec形式(= [\u0026quot;実行コマンド\u0026quot;, \u0026quot;引数\u0026quot;...]の形式)では展開されないため、シェル形式(= 実行コマンド 引数...)で記す必要がある。 または、ラッパースクリプトを指定するという手もアリだろう。    Instructions CMD コンテナのデフォルトの実行コマンド、またはその引数を指定する。\nCMD [\u0026#34;実行ファイル\u0026#34;, \u0026#34;ARG1\u0026#34;, \u0026#34;ARG2\u0026#34;, ...] # exec実行形式CMD [\u0026#34;ARG1\u0026#34;, \u0026#34;ARG2\u0026#34;, ...] # ENTRYPOINTのデフォルト引数CMD \u0026lt;コマンド...\u0026gt; # シェル形式 ２番目は ENTRYPOINT を指定した時、その引数となる。  docker run \u0026lt;コンテナ\u0026gt; 引数... として上書きできる   1, 3番目の形式は ENTRYPOINT と一緒には指定できない（はず…）  シェル形式の場合、 /bin/sh -c で起動されるようだ    ENTRYPOINT コンテナのデフォルトの実行コマンドを指定する。\nENTRYPOINT [\u0026#34;実行ファイル\u0026#34;, \u0026#34;ARG1\u0026#34;, \u0026#34;ARG2\u0026#34;, ...] # exec形式ENTRYPOINT 実行ファイル ARG1 ARG2 ... # シェル形式 上書きするには --entrypoint \u0026lt;コマンド...\u0026gt; とする。 シェル形式の場合、 /bin/sh -c で起動されるようだ CMD でデフォルト引数を与えると、 ENTRYPOINT として指定した「コマンド + 引数」の後に CMD として与えた引数がくっつく。  FROMubuntuENTRYPOINT [\u0026#34;top\u0026#34;, \u0026#34;-b\u0026#34;]CMD [\u0026#34;-c\u0026#34;]このコンテナを docker run で動かすと、 top -b -c が実行される（はず）。\nVOLUME docker run の -v オプションに相当。\nホストのディレクトリをコンテナにマウントする。\n参考:\n DockerのVolume機能について実験してみたことをまとめます - Qiita  Tips CMDとENTRYPOINTがどう作用するか http://docs.docker.jp/engine/reference/builder.html#cmd-entrypoint\n","excerpt":"公式リファレンス: https://docs.docker.com/engine/reference/builder/ 邦訳: Dockerfile リファレンス — Docker-docs-ja ド …","ref":"/tech-notes/a/software/docker/dockerfile/","title":"Dockerfile"},{"body":"リファレンス: https://docs.docker.com/engine/reference/commandline/cli/\nv17.0.3でのコマンド体系再編について 2017年1月にリリースされたv1.13（v17.0.3）でコマンド体系が再編された。\n古いコマンドも2020年4月現在では、まだ使えるものが多そうだが、注意が必要。\n参考:\n docker container / image コマンド新旧比較 - Qiita  チートシート version, helpの確認 # Help docker --help docker \u0026lt;COMMAND\u0026gt; --help # client/server version 表示 docker version See also https://docs.docker.com/engine/reference/commandline/version/\nコンテナの起動（実行） # コマンド実行 % docker run ubuntu /bin/echo \u0026#34;Hello, world\u0026#34; #=\u0026gt; Hello, world # bash を起動し、インタラクティブモードになる % docker run -it ubuntu /bin/bash root@b171dd1d7831:/# # バックグラウンドで hello world を1秒おきに出力し続ける % docker run -d ubuntu /bin/sh -c \u0026#34;while true; do echo hello world; sleep 1; done\u0026#34; c6e58ecccfdb5640938443911f85fa301338e0063afe1a13ab0ffc7c93aa7f5f # container id # Web サーバをホストのエフェメラルポートで動かす docker run -dP training/webapp python app.py # Web サーバをホストの 80番ポートで動かす docker run -d -p 80:5000 training/webapp python app.py # Web サーバを \u0026#34;web\u0026#34; という名前で動かす docker run -dP --name web training/webapp python app.py # Postgres サーバを \u0026#34;db\u0026#34; を、独自ネットワーク上で起動 docker run -d --net my-network --name db training/postgres # Web サーバに /webapp というボリュームを作って起動 docker run -dP --name web -v /webapp training/webapp python app.py # + ホストのマウントパス指定 docker run -dP --name web -v /var/lib/docker/volumes/data-webapp:/opt/webapp training/webapp python app.py # + ホストの共有領域のデータボリュームをディレクトリ名で指定(パスは上と同じになる) docker run -dP --name web -v data-webapp:/opt/webapp training/webapp python app.py See also run\nコンテナ操作(run 以外) # コンテナを作成するが起動しない。オプションは run に似ている docker create [OPTIONS] \u0026lt;IMAGE\u0026gt; [COMMAND] # 停止 docker stop $NAME_OR_ID # 再起動 docker start $NAME_OR_ID # 強制停止 docker kill $ID # コンテナ上でインタラクティブシェル(bash)実行 docker exec -it db bash # 作成した停止済みのコンテナを削除 docker rm $NAME_OR_ID # 停止しているコンテナの全削除。動作中のものはエラーになる docker rm `docker ps -a -q` コンテナの情報を見る # 動作中のコンテナ表示 docker ps # 停止しているものも含めて表示 docker ps -a # 停止していようがいまいが一番最近動かしたやつを表示 docker ps -l # top docker top $NAME_OR_ID # コンテナにマッピングされたホストのポートを表示 docker port $NAME_OR_ID \u0026lt;PORT\u0026gt; # ログ表示 docker logs $NAME_OR_ID # ログを tail -f する docker logs -f $NAME_OR_ID # コンテナの情報を JSON で dump docker inspect $NAME_OR_ID # + クエリで情報を絞り込む例 x 2: docker inspect --format=\u0026#39;{{json .NetworkSettings.Networks}}\u0026#39; $NAME_OR_ID docker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; $NAME_OR_ID コンテナのイメージ操作 # 変更を施したコンテナからイメージを作成する docker commit -m \u0026#34;変更についてのコメント\u0026#34; -a \u0026#34;名前 \u0026lt;メアド\u0026gt;\u0026#34; $NAME_OR_ID [\u0026lt;リポジトリ\u0026gt;[:タグ]] # Dockerfile からイメージ作成 docker build -t リポジトリ:タグ path/to/[Dockerfile] # イメージにタグを付ける docker tag $IMAGE_ID リポジトリ:タグ # リポジトリにあるイメージを検索 docker search \u0026lt;キーワード\u0026gt; # イメージをリポジトリから取得 docker pull \u0026lt;イメージ\u0026gt; # イメージをリポジトリに push docker push リポジトリ # ローカルにあるイメージ一覧 docker images # イメージ削除 docker rmi $ID データボリューム操作 See volume\nネットワーク操作 See network\n不要なイメージ・ボリューム等の掃除 # 停止したコンテナを削除 docker container prune # 不要ボリュームを削除 docker volume prune # 古いイメージなどを削除 docker image prune # ネットワークの掃除 docker network prune # まとめて掃除 docker system prune 参考:\n Dockerのあれこれを断捨離する - Qiita docker volume pruneコマンドの使い方（実例付）CE対応 | めもたんす  リファレンス container コンテナ操作。\n# コンテナ一覧 docker container ls [-a] # コンテナ停止 docker container stop CONTAINER_ID_OR_NAME # コンテナ削除 docker container rm CONTAINER_ID_OR_NAME # 停止したコンテナを全て削除 docker container prune # コンテナ上でインタラクティブシェル(bash)実行 docker container exec -it CONTAINER_ID_OR_NAME bash cp https://docs.docker.com/engine/reference/commandline/cp/\nホスト - コンテナ間でファイル/ディレクトリのコピー\nSyntax:\ndocker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH image イメージ操作。\n# 一覧 docker image list [-a] # Dockerfile からイメージ作成 docker image build -t リポジトリ:タグ \u0026lt;Dockerfileがあるディレクトリ\u0026gt; # イメージ削除 docker image rm IMAGE_ID network https://docs.docker.com/engine/reference/commandline/network/\nネットワークの管理\n# ネットワーク一覧 docker network ls # 特定ネットワークの情報表示 docker network inspect $NW_NAME # コンテナをネットワークから切断 docker network disconnect $NW_NAME $CONTAINER_NAME_OR_ID # コンテナをネットワークに接続 docker network connect $NW_NAME $CONTAINER_NAME_OR_ID # 独自ネットワークを作成 docker network create -d $DRIVER $NW_NAME run run はコンテナ起動コマンド。\n   オプション 意味     -d, \u0026ndash;detach バックグラウンドでコンテナを動かす   -e, \u0026ndash;env 環境変数を1つずつ指定   \u0026ndash;env-file  ファイルを指定して、環境変数を設定   -i, \u0026ndash;interactive STDIN を開く   \u0026ndash;name NAME コンテナに名前をつける   \u0026ndash;net NW ネットワーク NW に配置する。未指定だとデフォルトのネットワークになる   -P, \u0026ndash;publish-all コンテナが外部に開くポートをすべてランダムにホストのエフェメラルポートに割当てる   -p, \u0026ndash;publish=[] ポートを指定してポートを公開する   \u0026ndash;privileged 特権を付与   \u0026ndash;restart=\u0026lt;string\u0026gt; コンテナが既に存在するときの再起動ポリシー。デフォルトは no. 他に always が指定可能   \u0026ndash;rm コンテナ停止時に削除   -t, \u0026ndash;tty TTY 割当て   -v, \u0026ndash;volume=[] データボリュームのマウント    volume https://docs.docker.com/engine/reference/commandline/volume/\nデータボリュームの管理\n# ボリューム作成 docker volume create [OPTIONS] # flocker driver を使い my-named-volume という名前で 20GB のボリュームを作成 docker volume create -d flocker --name my-named-volume -o size=20GB # 一覧 docker volume ls # dangling volume をリスト docker volume ls -f dangling=true # 削除 docker volume rm $VOLUME_NAME 参考 非公式リファレンス系:\n Dockerチートシート - Qiita docker コマンド チートシート - Qiita Dockerコマンドラインリファレンス  その他:\n Dockerで不要になったコンテナやイメージを削除する - @znz blog (ヽ´ω) \u0026lt; DockerのOperation not permittedとの戦争 - (ヽ´ω) \u0026lt; *****  ","excerpt":"リファレンス: https://docs.docker.com/engine/reference/commandline/cli/\nv17.0.3でのコマンド体系再編について 2017年1月にリリース …","ref":"/tech-notes/a/software/docker/cmd/","title":"dockerコマンド"},{"body":"4/29 Ubuntu 18.04でIntelliJ IDEAを2020.1にアップデート 久しぶりに起動したらアップデートする必要があった。\n2018.1にアップデートしたときのログ\n上と同じ手順で行けた。\n以下はログ。\ntar.gzをダウンロードして解凍し、 $HOME/vendor/ に配置。\nidea-IC -\u0026gt; idea-IC-181.4203.550 とsymlinkしていたので、付け替える。\ncd ~/vendor rm idea-IC ln -s idea-IC-201.6668.121 idea-IC ~/.local/share/applications/jetbrains-idea-ce.desktop を次のように編集:\n[Desktop Entry] Version=2020.1.0 Type=Application Name=IntelliJ IDEA Community Edition Icon=$HOME/vendor/idea-IC/bin/idea.png Exec=\u0026quot;$HOME/vendor/idea-IC/bin/idea.sh\u0026quot; %f Comment=The Drive to Develop Categories=Development;IDE; Terminal=false StartupWMClass=jetbrains-idea-ce ※ $HOME は展開して書き替えないといけないかも。\nUbuntuに昔入れたminikubeをUninstall localkubeというdaemonが動いていることに気がついたのがきっかけだけど、2〜3年使っていないので掃除することにした。\n実行したコマンド:\nsudo systemctl stop localkube sudo systemctl disable localkube docker system prune rm -rf ~/.minikube sudo rm /usr/local/bin/localkube /usr/local/bin/minikube sudo rm -rf /etc/kubernetes/ 2017年の作業ログによると、dpkgで入れたみたいなんだけど、 dpkg -l しても出てこなかった。はて。\n参考:\n Uninstall Minikube - yuda prama - Medium How to uninstall? · Issue #1043 · kubernetes/minikube  mdBookについて少し機能を調べた https://rust-lang.github.io/mdBook/\nRust製のGitBookみたいなもの。\n高速でよさそう。\nMEMO:\n config: https://rust-lang.github.io/mdBook/format/config.html サイドバーに目次ツリーが表示されているが、 [output.html.fold] で挙動を変えられそう。  https://github.com/rust-lang/mdBook/pull/1027   目次（Table of Contents）は公式サポートないのかも。イシューになってる  {{#toc}}{{/toc}} で行けるんじゃないのかな？  https://rust-lang.github.io/mdBook/format/theme/index-hbs.html#1-toc   https://github.com/rust-lang/mdBook/issues/153 自作している人がいる  https://github.com/badboy/mdbook-toc      ","excerpt":"4/29 Ubuntu 18.04でIntelliJ IDEAを2020.1にアップデート 久しぶりに起動したらアップデートする必要があった。\n2018.1にアップデートしたときのログ\n上と同じ手順で …","ref":"/tech-notes/a/memo/20200429/","title":"2020-04-29"},{"body":"4/28 Macでanyenv経由のnodenv経由でNode.jsを入れてみた 以前はnodebrewを使っていたのだけど、anyenv押しの記事を見たので。\n参考:\n Homebrew 経由の anyenv 経由の nodenv 経由で Node.js をインストールする - Qiita https://github.com/anyenv/anyenv https://github.com/nodenv/nodenv  anyenv install\nbrew install anyenv anyenv init # 指示に従う vi .zshrc #=\u0026gt; eval \u0026#34;$(anyenv init -)\u0026#34; をいい感じに足す exec $SHELL -l nodenv install\nanyenv install nodenv eval \u0026#34;$(nodenv init -)\u0026#34; nodenv install 12.16.2 nodenv global 12.16.2 eval \u0026quot;$(nodenv init -)\u0026quot; はインストール後に1度だけ実行が必要そう。\nでないと、 ~/.anyenv/envs/nodenv/shims/ 以下に実行ファイルができないっぽい。（ちょっとハマった。）\n","excerpt":"4/28 Macでanyenv経由のnodenv経由でNode.jsを入れてみた 以前はnodebrewを使っていたのだけど、anyenv押しの記事を見たので。\n参考:\n Homebrew …","ref":"/tech-notes/a/memo/20200428/","title":"2020-04-28"},{"body":"複数行のコメントアウト : とヒアドキュメントを組み合わせる。\n: \u0026lt;\u0026lt; \u0026#34;__EOCOMMENT__\u0026#34; コメントアウトしたいコード __EOCOMMENT__ 参考:\n bashで複数行コメントアウトする方法 - Qiita  論理演算 ((2 \u0026gt; 1)) # $? =\u0026gt; 0 ((1 \u0026gt; 1)) # $? =\u0026gt; 1 (($(seq 1 3 | wc -w) \u0026gt; 2)) # $? =\u0026gt; 0 if true; then echo ok; fi #=\u0026gt; ok 数値の操作 i=0 echo $((i++)) #=\u0026gt; 0 echo $((++i)) #=\u0026gt; 2 連番によるループ $ n=0 $ for i in $(seq $n $((n + 2))); do echo $i; done 0 1 2 文字列操作 部分文字列の削除 以下、 Bash scripting より。\n ${var%pattern} … 後方からパターンの最短マッチを削除 ${var%%pattern} … 後方からパターンの最長マッチを削除 ${var#pattern} … 前方からパターンの最短マッチを削除 ${var##pattern} … 前方からパターンの最長マッチを削除  パスからディレクトリ名やファイル名を取り出すのによく使う。\nfullpath=/a/b/c.txt echo ${fullpath##*/} # c.txt echo ${fullpath%/*} # /a/b filename=d.e.txt echo ${filename%.*} # d.e echo ${filename##*.} # txt たぶん、Bash に限らず POSIX で使える。\n下に載ってる。\nhttp://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_06_02\n文字列の部分切り出し $ echo $str 1234567890 $ echo ${str:3:4} 4567 参考:\n シェルスクリプトで部分文字列を切り出す - 理系学生日記  文字列を部分的に置換  ${var/x/y} \u0026hellip; $var 文字列の x を y に置換（1回のみ） ${var//x/y} \u0026hellip; $var 文字列の x を y に置換（全てマッチ）  参考: bashの変数をsplitして配列を作る方法: 小粋空間\n","excerpt":"複数行のコメントアウト : とヒアドキュメントを組み合わせる。\n: \u0026lt;\u0026lt; \u0026#34;__EOCOMMENT__\u0026#34; コメントアウトしたいコード __EOCOMMENT__ 参考: …","ref":"/tech-notes/a/cli/bash/cookbook/","title":"Cookbooks"},{"body":"4/27 Cloud Build + TerraformでインフラCI/CD 参考記事:\n Terraform、Cloud Build、GitOps を使用してインフラストラクチャをコードとして管理する | ソリューション Infrastructure as Code: Introduction to Continuous Spark Cluster Deployment with Cloud Build and Terraform  Bitbucket Pipelines + Terraform 参考:\n Terraform with Bitbucket pipeline How to build self-deploying applications with Terraform and BitBucket Pipelines. | Nick Santamaria  tfnotify対応 help wanted\nSupport Bitbucket Pipelines · Issue #36 · mercari/tfnotify\nGCP対応 terraformのDockerイメージを使って、下の要領で認証情報を渡してあげれば行けると思われる。\nBitbucket PipelinesでGCPに継続的デリバリ 参考:\n Deploy to Google Cloud - Atlassian Documentation Testing \u0026amp; deploying Google Cloud Functions in BitBucket Pipelines | PrimitiveSense - Web Design Newcastle Bitbucket Pipelines deployment to a Google Container Engine configuration Dev Story: Deploy to GCP Cloud Run with Bitbucket Pipelines  ","excerpt":"4/27 Cloud Build + TerraformでインフラCI/CD 参考記事:\n Terraform、Cloud Build、GitOps を使用してインフラストラクチャをコードとして管理す …","ref":"/tech-notes/a/memo/20200427/","title":"2020-04-27"},{"body":"Documentation  https://cloud.google.com/kubernetes-engine/docs/?hl=ja https://cloud.google.com/kubernetes-engine/quotas?hl=ja  ベストプラクティス  Best Practices for Operating Containers | Architectures | Google Cloud  Logging, etc.   Kubernetes best practices: terminating with grace | Google Cloud Blog  仕様  クラスタ オートスケーラー | Kubernetes Engine のドキュメント | Google Cloud  クラスタの自動スケーリング | Kubernetes Engine のドキュメント | Google Cloud    Quota https://cloud.google.com/kubernetes-engine/quotas\nLast updated at 2020-04-13\n GKEクラスタごと  クラスタあたりの最大ノード数: 5,000 ノードプールあたりの最大ノード数: 1,000 ノードあたりの最大ポッド数: 110    限定公開クラスタ Docs:\n 限定公開クラスタの設定 | Kubernetes Engine のドキュメント | Google Cloud https://cloud.google.com/sdk/gcloud/reference/container/clusters/create?hl=ja Example GKE Setup | Cloud NAT | Google Cloud  要点:\n ノードは内部IPアドレスのみを持つため、インターネットから隔離される 限定公開クラスタでは、マスターへのアクセスを制御できる LB経由で受信トラフィックを受けられる。また、内部LB経由でVPC内のトラフィックを受けることもできる 外と通信したいときは、上記の「Example GKE Setup」にあるように、Cloud NAT + Cloud Routerをセットアップする  Tips:\n (2019-12-02現在) gcloud container clusters create コマンドでは --enable-private-nodes --master-ipv4-cidr \u0026lt;CIDR\u0026gt; オプションをつける  負荷分散  https://cloud.google.com/kubernetes-engine/docs/concepts/ingress  HTTP(S) 負荷分散 Ingressで複数のバックエンドServiceを設定できる。設定例:\napiVersion:extensions/v1beta1kind:Ingressmetadata:name:my-ingressspec:rules:- http:paths:- path:/*backend:serviceName:my-productsservicePort:60000- path:/discountedbackend:serviceName:my-discounted-productsservicePort:80Managed SSL certificateを使う https://cloud.google.com/kubernetes-engine/docs/how-to/managed-certs\n GCPの静的IPを払い出し、対象のDNSレコードに設定する必要がある  See also https://sites.google.com/site/progrhymetechwiki/cloud/gcp/gclb#TOC-SSL-\nHTTPの無効化 https://cloud.google.com/kubernetes-engine/docs/concepts/ingress?hl=ja#disabling_http\nHTTPSのみを使うときはアノテーション kubernetes.io/ingress.allow-http の値を \u0026quot;false\u0026quot; に設定する。\napiVersion:extensions/v1beta1kind:Ingressmetadata:name:my-ingress-2annotations:kubernetes.io/ingress.allow-http:\u0026#34;false\u0026#34;spec:tls:- secretName:my-secret...※2020-03-04現在、K8sのバージョンによっては、マネージドSSL証明書を使う場合は、 ingress.gcp.kubernetes.io/pre-shared-cert アノテーションの値に証明書名を入れる必要がある。1.15.x-gke.y の場合は自動でアノテーション付けてくれるっぽい。\nSee https://github.com/kubernetes/ingress-gce/issues/1001\n内部TCP/UDP負荷分散 内部 TCP / UDP 負荷分散 | Kubernetes Engine のドキュメント | Google Cloud\n2020-03-25現在、β版\n Serviceを type: LoadBalancer で作成し、所定のannotationを入れる 内部LBが作成される Ingressは不要 Compute InstanceGroupで振り分けされる  2020-03-25現在、ネットワークエンドポイントグループには対応していない   同じDeploymentで、内部LBのServiceと外部HTTP(S)負荷分散用の2つのServiceを持つことができる  Example:\napiVersion:v1kind:Servicemetadata:name:ilb-serviceannotations:cloud.google.com/load-balancer-type:\u0026#34;Internal\u0026#34;labels:app:hellospec:type:LoadBalancerselector:app:helloports:- port:80targetPort:8080protocol:TCPBackendConfig（β on 2020-04-27） https://cloud.google.com/kubernetes-engine/docs/concepts/backendconfig?hl=en\nGKE固有のcustom resource.\nBackendConfigによって、HTTP(S) Load Balancingに以下の機能を設定できる:\n Cloud CDN Cloud Armor Identity-Aware Proxy (IAP) Timeout, Connection draining timeout, Session affinity, User-defined request headers  Example:\n タイムアウトを40秒に設定 接続ドレインタイムアウトを60秒に設定  apiVersion:cloud.google.com/v1beta1kind:BackendConfigmetadata:name:my-bsc-backendconfigspec:timeoutSec:40connectionDraining:drainingTimeoutSec:60Horizontal Pod Autoscaler HPA.\n 水平ポッド自動スケーリング | Kubernetes Engine のドキュメント | Google Cloud  外部指標によるデプロイの自動スケーリング | Kubernetes Engine のチュートリアル | Google Cloud カスタム指標でのデプロイの自動スケーリング | Kubernetes Engine のチュートリアル | Google Cloud いずれもCloud Monitoringメトリクスでスケール設定を行う https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter をクラスタにデプロイする    参考:\n https://sites.google.com/site/progrhymetechwiki/software/k8s#TOC-Horizontal-Pod-Autoscaler Autoscaling K8s HPA with Google HTTP/S Load-Balancer RPS EXTERNAL Stackdriver Metrics  How-to アップグレード https://cloud.google.com/kubernetes-engine/docs/how-to/upgrading-a-cluster\nTips:\n リリースチャネルを指定することで、自動アップグレードできる  kubeconfigエントリを生成 gcloud container clusters get-credentials [CLUSTER_NAME] [--project PROJECT] [--region REGION] ↑のコマンドは更に、クラスタをデフォルトのkubectlのcontextに設定する。\n参考:\n kubectl 用のクラスタ アクセスの構成 | Kubernetes Engine のドキュメント | Google Cloud  GKEのノードにSSH  高度な方法によるインスタンスへの接続 | Compute Engine ドキュメント | Google Cloud 限定公開クラスターのGKEノードにサクッとSSHする方法 - Qiita GKE で k8s クラスタの node に ssh する - Qiita  参考:\n Insufficient Permission: Request had insufficient authentication scopes. - Course: Google Certified Associate Cloud Engineer 2020  コンテナネイティブの負荷分散を使う コンテナ ネイティブの負荷分散を使用する | Kubernetes Engine のドキュメント | Google Cloud\nTL;DR:\n ネットワークエンドポイントグループ(NEG)を作成して、Podに均等にトラフィックを分配できる 従来の方式だとインスタンスグループ経由のアクセスで、iptablesを介してPodにアクセスしており、余分なネットワークオーバーヘッドが発生していた  既知の問題（2020-04-27時点）:\n GKEのガベージコレクションが2分間隔なので、LBが完全に削除される前にクラスタが削除された場合、NEGを手動で削除する必要がある Podのreadinessフィードバックを使っていない場合、ワークロードをデプロイするときや再起動するときに、ワークロードの更新完了に要する時間よりも、新しいエンドポイントの伝播に要する時間のほうが長くなる場合がある  Topics Logging  Google Kubernetes Engine の Stackdriver ログを Fluentd でカスタマイズする | ソリューション  参考  GKE上RailsのアプリケーションログをStackdriver Loggingで運用する方法 - Riki Shimma - Medium  ","excerpt":"Documentation  https://cloud.google.com/kubernetes-engine/docs/?hl=ja …","ref":"/tech-notes/a/gcp/gke/","title":"Google Kubernetes Engine"},{"body":"Documentation https://cloud.google.com/load-balancing/docs/\n概要  HTTP(S) 負荷分散のコンセプト | 負荷分散 | Google Cloud バックエンド サービスについて | 負荷分散 | Google Cloud  Spec  IP anycast対応 アーキテクチャ:  グローバル負荷分散によるアプリケーションの処理能力の改善 | アーキテクチャ | Google Cloud \u0026hellip; IP anycast, GFE    SSL証明書 https://cloud.google.com/load-balancing/docs/ssl-certificates\n マネージド証明書  Let\u0026rsquo;s Encrypt DV 自動更新 ワイルドカードドメインは不可    接続ドレイン コネクション ドレインの有効化 | 負荷分散 | Google Cloud\nコネクションドレインとも表記される。（公式ドキュメント統一してくれ）\n コネクション ドレインとは、VM がインスタンス グループから除外されたときに、既存の進行中リクエストに完了までの時間が確実に与えられるようにするプロセスです。\nコネクション ドレインを有効にするには、バックエンド サービスでコネクション ドレイン タイムアウトを設定します。タイムアウト時間は 1～3,600 秒に設定してください。\n デフォルトONでいいんじゃないかと思うのだが、2020-04-27現在は、上記のように設定が必要。\n次のLBのバックエンドサービスで使える:\n HTTP(S) ロードバランサ TCP プロキシ ロードバランサ SSL プロキシ ロードバランサ 内部 HTTP(S) ロードバランサ 内部 TCP / UDP ロードバランサ  外部HTTP(S)負荷分散 バックエンドバケット ロードバランサへの Cloud Storage バケットの追加 | 負荷分散 | Google Cloud\nCloud Storageバケットをバックエンドに追加し、パスで振り分けることができる。\nLogging HTTP(S) 負荷分散のロギングとモニタリング | Google Cloud\nTopics GCLBとCDNによる動的サイト高速化 グローバル負荷分散によるアプリケーションの処理能力の改善 | アーキテクチャ | Google Cloudにあるように、GCLBを前段に置いたサービスでは、GFEによるネットワーク経路最適化やTLS終端の恩恵を得られる。\n従って、APIの動的サイト高速化をねらいとしてCDNを入れる意味は薄い。\n特に、全くキャッシュをしない場合、CDNを入れても入れなくてもほとんど変わらない、とGoogle Cloudの中の人が言っていた。（無意味ではないけど、ネットワークのゆらぎぐらいの差らしい）\n","excerpt":"Documentation https://cloud.google.com/load-balancing/docs/\n概要  HTTP(S) 負荷分散のコンセプト | 負荷分散 | Google …","ref":"/tech-notes/a/gcp/lb/","title":"Cloud Load Balancing"},{"body":"Provider Configuration  max_retries \u0026hellip; APIのリトライ回数を指定できる  Data Sources acm_certificate https://www.terraform.io/docs/providers/aws/d/acm_certificate.html\nACM証明書の情報取得\n参考:\n Terraform v0.7.9 でACMのデータソースが導入されました ｜ Developers.IO ACMで取得した証明書をterraformで配置する - tjinjin\u0026rsquo;s blog  caller_identity https://www.terraform.io/docs/providers/aws/d/caller_identity.html\nTerraform実行中のAWSアカウントのID等の情報を取得する。\n参考:\n *.tf 内で AWS アカウント ID を自動参照(取得)する aws_caller_identity Data Source - Qiita  iam_policy_document https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html\nIAM PolicyのJSONをHCLっぽく定義できる。\nJSONテンプレートより融通が効くし、syntax checkも掛かるので、便利なことがある。\nregion https://www.terraform.io/docs/providers/aws/d/region.html\nprovider で設定したリージョンを取得できる。\nsns_topic https://www.terraform.io/docs/providers/aws/d/sns_topic.html\nSNS TopicのARNを取得できる。\nssm_parameter https://www.terraform.io/docs/providers/aws/d/ssm_parameter.html\nEC2 Parameter Storeからデータ取得\n# \u0026#34;foo\u0026#34;という名前のパラメータストアを取得 data \u0026#34;aws_ssm_parameter\u0026#34; \u0026#34;foo\u0026#34; { name = \u0026#34;foo\u0026#34; }  SecureString であっても特にKSM keyを指定する必要はない。内部的にdecryptしてくれるみたい。  \u0026ldquo;terraformのstateの中ではraw textで保存されるから気をつけてね\u0026quot;って書いてある。    参考:\n terraform と パラメータストア - yBlog https://aws.amazon.com/jp/ec2/systems-manager/parameter-store/  Resources appautoscaling関連 Application AutoScaling.\nECS Serviceなどのオートスケール設定。\n https://www.terraform.io/docs/providers/aws/r/appautoscaling_policy.html https://www.terraform.io/docs/providers/aws/r/appautoscaling_target.html  autoscaling関連  https://www.terraform.io/docs/providers/aws/r/autoscaling_group.html https://www.terraform.io/docs/providers/aws/r/launch_configuration.html  cloudwatch関連  https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_group.html  retention_in_days \u0026hellip; ログの保持期間。とり得る値は http://docs.aws.amazon.com/ja_jp/AmazonCloudWatchLogs/latest/APIReference/API_PutRetentionPolicy.html に示されている。 0 を指定すると無期限になる。   https://www.terraform.io/docs/providers/aws/r/cloudwatch_log_subscription_filter.html  ElasticsearchやKinesisにサブスクライブするやつ   https://www.terraform.io/docs/providers/aws/r/cloudwatch_metric_alarm.html  CloudWatch Alarmによる監視の作成 namespaceに指定する値は https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/monitoring/aws-namespaces.html を参照。 各namespaceで有効なmetric_nameやdimentionsフィールドの名前もAWSドキュメントを参照する。   https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_rule.html  schedule_expression の書式は http://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/events/ScheduledEvents.html   https://www.terraform.io/docs/providers/aws/r/cloudwatch_event_target.html  ec2関連  https://www.terraform.io/docs/providers/aws/r/ami.html https://www.terraform.io/docs/providers/aws/r/ebs_volume.html https://www.terraform.io/docs/providers/aws/r/eip.html https://www.terraform.io/docs/providers/aws/r/instance.html  ecs関連  https://www.terraform.io/docs/providers/aws/r/ecr_repository.html https://www.terraform.io/docs/providers/aws/r/ecr_repository_policy.html https://www.terraform.io/docs/providers/aws/r/ecs_cluster.html https://www.terraform.io/docs/providers/aws/r/ecs_service.html  placement_strategy \u0026hellip; ECSタスク配置戦略。See https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task-placement-strategies.html   https://www.terraform.io/docs/providers/aws/r/ecs_task_definition.html  指定可能なパラメーターについては、タスク定義パラメーター - Amazon Elastic Container Service を参照。    動的ポートマッピングをする場合、task_definitionでhostPortを0にする:\n# ecs_task_definition.tf resource \u0026#34;aws_ecs_task_definition\u0026#34; \u0026#34;service\u0026#34; { : container_definitions = \u0026#34;${file(\u0026#34;task-definitions/service.json\u0026#34;)}\u0026#34; : }# task_definitions/service.json [ { : \u0026#34;portMappings\u0026#34;: [ { \u0026#34;containerPort\u0026#34;: 3000, \u0026#34;hostPort\u0026#34;: 0, ] }, : ] 参考:\n terraformで開発者個人別に自由にECSにコンテナをデプロイできる開発環境を用意する - Qiita TerraformでECS+ECRする話  elasticsearch関連  https://www.terraform.io/docs/providers/aws/r/elasticsearch_domain.html  Exported Attributes:  domain_id \u0026hellip; ${AWSアカウントID}/${クラスタ名} . 監視のdimentionとしてはそのままでは使えない。     https://www.terraform.io/docs/providers/aws/r/elasticsearch_domain_policy.html  iam関連  https://www.terraform.io/docs/providers/aws/r/iam_access_key.html https://www.terraform.io/docs/providers/aws/r/iam_group.html https://www.terraform.io/docs/providers/aws/r/iam_group_policy_attachment.html https://www.terraform.io/docs/providers/aws/r/iam_instance_profile.html https://www.terraform.io/docs/providers/aws/r/iam_policy.html https://www.terraform.io/docs/providers/aws/r/iam_role.html https://www.terraform.io/docs/providers/aws/r/iam_role_policy.html https://www.terraform.io/docs/providers/aws/r/iam_user.html https://www.terraform.io/docs/providers/aws/r/iam_user_policy.html \u0026hellip; 当該IAM Userにだけつけるインラインポリシー https://www.terraform.io/docs/providers/aws/r/iam_user_policy_attachment.html policyとroleの紐付け  https://www.terraform.io/docs/providers/aws/r/iam_policy_attachment.html  policy : roleが1対多。コード化されていないroleへの紐付けは削除される。   https://www.terraform.io/docs/providers/aws/r/iam_role_policy_attachment.html  policy : roleが1対1.      kms関連  https://www.terraform.io/docs/providers/aws/r/kms_alias.html \u0026hellip; alias for KMS key https://www.terraform.io/docs/providers/aws/r/kms_key.html \u0026hellip; KMS master keyの作成・管理  lambda関連  https://www.terraform.io/docs/providers/aws/r/lambda_function.html  runtime \u0026hellip; 利用できるruntimeについては CreateFunction - AWS Lambda を見る。   https://www.terraform.io/docs/providers/aws/r/lambda_permission.html  マネジメントコンソールだと\u0026quot;Triggers\u0026quot;のタブ 許可したリソースからLambdaを実行することができる    lb関連 ALB等の作成・管理:\n https://www.terraform.io/docs/providers/aws/r/lb.html https://www.terraform.io/docs/providers/aws/r/lb_listener.html https://www.terraform.io/docs/providers/aws/r/lb_target_group.html  CLB:\n https://www.terraform.io/docs/providers/aws/r/elb.html  rds関連  https://www.terraform.io/docs/providers/aws/r/db_event_subscription.html \u0026hellip; RDSイベント通知 https://www.terraform.io/docs/providers/aws/r/rds_cluster.html \u0026hellip; Aurora用(?) https://www.terraform.io/docs/providers/aws/r/rds_cluster_instance.html \u0026hellip; Aurora用(?) https://www.terraform.io/docs/providers/aws/r/db_instance.html ~~https://www.terraform.io/docs/providers/aws/r/db_subnet_group.html~~ \u0026hellip; これはEC2 Classic用でもう使うことはなさそう。 https://www.terraform.io/docs/providers/aws/r/db_security_group.html https://www.terraform.io/docs/providers/aws/r/rds_cluster_parameter_group.html https://www.terraform.io/docs/providers/aws/r/db_parameter_group.html  route53関連  https://www.terraform.io/docs/providers/aws/r/route53_zone.html  vpc_id を指定するとPrivate Hosted Zoneになる。 delegation_set_id を指定するとPublic Hosted Zoneになる。   https://www.terraform.io/docs/providers/aws/r/route53_record.html  Route53のDNSレコード作成・管理    s3関連  https://www.terraform.io/docs/providers/aws/r/s3_bucket.html https://www.terraform.io/docs/providers/aws/r/s3_bucket_policy.html  sns関連  https://www.terraform.io/docs/providers/aws/r/sns_topic.html https://www.terraform.io/docs/providers/aws/r/sns_topic_policy.html https://www.terraform.io/docs/providers/aws/r/sns_topic_subscription.html  ※emailのサブスクリプションは作成できない。メール認証が必要なので。    vpc関連  https://www.terraform.io/docs/providers/aws/r/default_route_table.html  これはimportに対応していない route_table + main_route_table_associationで代替できそう   https://www.terraform.io/docs/providers/aws/r/main_route_table_assoc.html https://www.terraform.io/docs/providers/aws/r/route.html  route_tableと一緒に使うとまずそう   https://www.terraform.io/docs/providers/aws/r/route_table.html https://www.terraform.io/docs/providers/aws/r/subnet.html https://www.terraform.io/docs/providers/aws/r/vpc.html  Route 53のPrivate DNSを使うには、 enable_dns_hostnames, enable_dns_support を true にする。    budgets_budget https://www.terraform.io/docs/providers/aws/r/budgets_budget.html\nBudgetにコストアラートを設定できたり。\ndynamodb_table https://www.terraform.io/docs/providers/aws/r/dynamodb_table.html\nDynamoDB table作成\nsecurity_group https://www.terraform.io/docs/providers/aws/r/security_group.html\nSecurity Groupの作成・管理\nsqs_queue https://www.terraform.io/docs/providers/aws/r/sqs_queue.html\nSQS Queueの作成・管理\nssm_parameter https://www.terraform.io/docs/providers/aws/r/ssm_parameter.html\nEC2 Parameter Storeにデータを保存する。\n","excerpt":"Provider Configuration  max_retries \u0026hellip; APIのリトライ回数を指定できる  Data Sources acm_certificate …","ref":"/tech-notes/a/software/terraform/provider/aws/","title":"AWS"},{"body":"Configuration Google Provider Configuration Reference - Terraform by HashiCorp\nSYNOPSIS:\nprovider \u0026#34;google\u0026#34; { //credentials = \u0026#34;${file(\u0026#34;account.json\u0026#34;)}\u0026#34; project = \u0026#34;my-project-id\u0026#34; region = \u0026#34;us-central1\u0026#34; zone = \u0026#34;us-central1-c\u0026#34; version = \u0026#34;3.19.0\u0026#34; } Resources GCP (IAM, API, Billing, Organization) Providerリファレンスで、「Google Cloud Platform Resources」というカテゴリに属するもの。\n google_project_service \u0026hellip; APIs \u0026amp; Servicesの有効化 google_service_account google_service_account_key  IAM policy for projects https://www.terraform.io/docs/providers/google/r/google_project_iam.html\n google_project_iam_policy google_project_iam_binding \u0026hellip; role : member = 1 : Nの権限を設定する。Service Accountの権限にも対応 google_project_iam_member \u0026hellip; role : member = 1 : 1の権限を設定する。Service Accountの権限にも対応 google_project_iam_audit_config  compute系  google_compute_backend_bucket \u0026hellip; HTTP(S) LBのバックエンドになるGCSバケット設定 google_compute_backend_service \u0026hellip; GCLBのバックエンドになるサービスの設定 google_compute_health_check \u0026hellip; ヘルスチェック google_compute_instance google_compute_managed_ssl_certificate \u0026hellip; β (2020-03-18) HTTPS LBのためのマネージドTLS証明書 google_compute_security_policy \u0026hellip; Cloud Armorのセキュリティポリシー  storage (GCS) 系  google_storage_bucket \u0026hellip; GCS (Cloud Storage) バケット google_storage_bucket_object \u0026hellip; GCSオブジェクト。ローカルのファイルからアップロードできる  google_cloudfunctions_function https://www.terraform.io/docs/providers/google/r/cloudfunctions_function.html\nCloud Function作成・管理\ngoogle_project_service https://www.terraform.io/docs/providers/google/r/google_project_service.html\nAPIサービスの有効化\n","excerpt":"Configuration Google Provider Configuration Reference - Terraform by HashiCorp\nSYNOPSIS:\nprovider …","ref":"/tech-notes/a/software/terraform/provider/google/","title":"Google"},{"body":"便利構文 https://www.terraform.io/docs/configuration/interpolation.html\n計算とか制御構文とか便利関数が有る。\nelement(list, index) listの要素を取得。\n最初の要素のindexは0.\nfile(path) content = \u0026#34;${file(path/to/file)}\u0026#34;# ファイルの内容を取り込む format(format, args, \u0026hellip;) url = \u0026#34;${format(\u0026#34;https://%s/%s\u0026#34;, var.fqdn, var.path)}\u0026#34; formatlist(format, args, \u0026hellip;) formatのlist版。 args... としてlistを受け取り、list値を返す。\nurls = \u0026#34;${formatlist(\u0026#34;https://%s/\u0026#34;, var.fqdn_list)}\u0026#34; lookup(map, key [, default]) mapの key に対するvalueを参照する。第3引数に見つからなかったときの default 値を指定することもできる。\n1階層のmapは stash[\u0026quot;x\u0026quot;] で良いが、デフォルト値を設定したいときや、2階層のmapでは lookup を使う必要がある。\nv = \u0026#34;${lookup(var.stash[\u0026#34;x\u0026#34;], \u0026#34;y\u0026#34;, \u0026#34;default-value\u0026#34;)}\u0026#34; keys(map) mapのキーをソート済みのlistとして返す。See also values\nmap(key, value, \u0026hellip;) mapを作る。\noutput \u0026#34;result\u0026#34; { value = \u0026#34;${map( \u0026#34;key-1\u0026#34;, \u0026#34;${value-1}\u0026#34;, \u0026#34;key-2\u0026#34;, \u0026#34;${value-2}\u0026#34;, : )}\u0026#34; } split(delim, string) 文字列をデリミタ文字で分割してlistを返す。\nExample:\n\u0026#34;${element(split(\u0026#34;/\u0026#34;, \u0026#34;dir/file\u0026#34;), 1)}\u0026#34; #=\u0026gt; \u0026#34;file\u0026#34; values(map) mapの値をlistとして返す。得られる値の順序は、対応するキーのlistが keys で返される順序と同じになるようである。\n","excerpt":"便利構文 https://www.terraform.io/docs/configuration/interpolation.html\n計算とか制御構文とか便利関数が有る。\nelement(list, …","ref":"/tech-notes/a/software/terraform/config/v0.11/","title":"v0.11"},{"body":"Documentation https://docs.npmjs.com/\n CLI documentation | npm Documentation  CLI Examples:\n# help npm help npm help \u0026lt;command\u0026gt; # バージョン表示 npm -v npm-install https://docs.npmjs.com/cli-commands/install.html\nパッケージをインストールする。\nエイリアス: i, add\n# 書式 npm install パッケージ [OPTIONS] npm install [\u0026lt;@scope\u0026gt;/]\u0026lt;name\u0026gt; npm install [\u0026lt;@scope\u0026gt;/]\u0026lt;name\u0026gt;@\u0026lt;version\u0026gt; # package.json に従ってインストール npm install    Option 説明     -g \u0026ndash;global   \u0026ndash;no-save （package.jsonの）dependencies に追加しない    npm-ls https://docs.npmjs.com/cli-commands/ls.html\nインストールされたパッケージを一覧表示。\nエイリアス: list, la, ll\nnpm ls [[\u0026lt;@scope\u0026gt;/]\u0026lt;pkg\u0026gt; ...] npm-uninstall https://docs.npmjs.com/cli-commands/uninstall.html\nインストールされたパッケージを削除する。\nエイリアス: remove, rm, un, unlink\nnpm uninstall パッケージ [OPTIONS] ","excerpt":"Documentation https://docs.npmjs.com/\n CLI documentation | npm Documentation  CLI Examples:\n# help …","ref":"/tech-notes/a/program/lang/js/node/npm/","title":"npm"},{"body":"Documentation  https://nodejs.org/api/  パッケージマネージャー  npm Yarn  Node.jsのバージョン管理  nodebrew nvm  Modules util https://nodejs.org/api/util.html\nutil.format https://nodejs.org/api/util.html#util_util_format_format_args\nprintfみたいなやつ。\nconsole.logなどが内部的に利用しているそうだ。\n参考:\n %o 便利 - Qiita  package.json プロジェクトで使うNode.js modulesを管理するためのファイル。\nバージョン記法 参考:\n package.json のチルダ(~) とキャレット(^) - Qiita  チルダ表記 ~ 明記したところ以下のバージョンがあがることのみ許容\n ~1.1.2 = 1.1.2 \u0026lt;= version \u0026lt; 1.2.0 ~1.1 = 1.1.x ~1 = 1.x  オリジナルの定義は、\n Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not.\n キャレット表記 ^ 一番左側にある、ゼロでないバージョニングは変えない (それ以下があがることは許容)\n ^1.2.3 := 1.2.3 \u0026lt;= version \u0026lt; 2.0.0 ^0.2.3 := 0.2.3 \u0026lt;= version \u0026lt; 0.3.0 ^0.0.3 := 0.0.3 \u0026lt;= version \u0026lt; 0.0.4  オリジナルの定義は\n Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple.\n ","excerpt":"Documentation  https://nodejs.org/api/  パッケージマネージャー  npm Yarn  Node.jsのバージョン管理  nodebrew nvm …","ref":"/tech-notes/a/program/lang/js/node/","title":"Node.js"},{"body":"JavaScript | MDN\nGetting Started  JavaScript ガイド - JavaScript | MDN  Reference:\n JavaScript リファレンス - JavaScript | MDN JavaScript and HTML DOM Reference  コーディング規約:\n Google JavaScript Style Guide  非公式和訳: Google JavaScript Style Guide 和訳 — Google JavaScript Style Guide 和訳   https://github.com/felixge/node-style-guide 参考まとめ:  JavaScriptのスタイルガイドまとめ(おすすめ4選) - Qiita    Reference Date https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Date\nJSON https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/JSON\nSYNOPSIS:\nconst obj = JSON.parse(str) const str = JSON.stringify(obj) Tips デバッグ  debugger; 文を埋め込む。  参考:\n JavaScriptのデバッグ方法 – JSを嫌いにならないためのTips | プログラミング | POSTD  日付と時刻の計算  【JavaScript】日付処理 - Qiita 日付と時刻の計算 (JavaScript)  Topics var, let, constの使い分け 2017年12月現在、イマイチよくわかっていない。\n参考:\n JavaScriptにおけるvar/let/constの使い分け  sprintfなさそう Node.jsだとutilがある:\n https://nodejs.org/api/util.html  npmもある:\n https://www.npmjs.com/package/sprintf  \u0026ldquo;0\u0026quot;埋めとか半角スペースで埋める方法としては substr を使った例が出て来る:\n Javascriptで文字列の０埋め、空白で右寄せでフォーマット - それマグで！  自作関数を作る例も出てくる:\n Javascriptで日付・時刻をフォーマット表示 - Qiita 日付フォーマットなど 日付系処理 - Qiita  日付時刻については、固定フォーマットで出力する関数はある。\n参考:\n 日付と時刻文字列 (JavaScript) 【Javascript入門】日付のフォーマット処理まとめ | 侍エンジニア塾ブログ | プログラミング入門者向け学習情報サイト  ","excerpt":"JavaScript | MDN\nGetting Started  JavaScript ガイド - JavaScript | MDN  Reference:\n JavaScript リファレンス - …","ref":"/tech-notes/a/program/lang/js/","title":"JavaScript"},{"body":"Ubuntu https://github.com/golang/go/wiki/Ubuntu\n2018年以前ぐらいまではtarballからインストールしていたと思うが、2020-04-26現在は、apt installが可能になっている。\n以下は最新版をインストールする手順:\nsudo add-apt-repository ppa:longsleep/golang-backports sudo apt update sudo apt install golang-go ","excerpt":"Ubuntu https://github.com/golang/go/wiki/Ubuntu\n2018年以前ぐらいまではtarballからインストールしていたと思うが、2020-04-26現在 …","ref":"/tech-notes/a/program/lang/go/install/","title":"Install"},{"body":" Marketplace \u0026hellip; 公開されているactionを見つけられる。  Actionとは About actions - GitHub Help\nactionはワークフローで実行される処理（タスク）を再利用可能な形にパッケージしたものである。\nActionの形式 https://help.github.com/en/actions/building-actions/about-actions#types-of-actions\n   Type Operating system     Docker container Linux   JavaScript Linux, MacOS, Windows    ワークフローからの利用 https://help.github.com/en/actions/configuring-and-managing-workflows/configuring-a-workflow#referencing-actions-in-your-workflow\nワークフローからは、次のロケーションのactionが利用できる:\n 公開リポジトリ 同リポジトリ内で参照できるもの Docker Hubに公開されたDockerイメージ  公式Actions GitHub公式のactionはたぶん https://github.com/actions にあるもの。\ncheckout https://github.com/actions/checkout\nリポジトリをチェックアウトする。\nおそらくほとんどのワークフローから利用される。\nExample:\n- uses:actions/checkout@v2with:# Number of commits to fetch. 0 indicates all history.# Default: 1fetch-depth:0# Whether to checkout submodules: `true` to checkout submodules or `recursive` to# recursively checkout submodules.## Default: falsesubmodules:truesetup-node https://github.com/actions/setup-node/\nNode.jsをセットアップ。\nBasic:\nsteps:- uses:actions/checkout@v2- uses:actions/setup-node@v1with:node-version:\u0026#39;10.x\u0026#39;- run:npminstall- run:npmtestMatrix Testing:\njobs:build:runs-on:ubuntu-18.04strategy:matrix:node:[\u0026#39;10.x\u0026#39;,\u0026#39;12.x\u0026#39;]name:Node${{matrix.node}}samplesteps:- uses:actions/checkout@v2- name:Setupnodeuses:actions/setup-node@v1with:node-version:${{matrix.node}}- run:npminstall- run:npmtest参考:\n GitHub ActionsでのNode.jsの利用 - GitHub ヘルプ https://github.com/actions/starter-workflows/blob/master/ci/node.js.yml  3rd Party Actions peaceiris/actions-gh-pages https://github.com/peaceiris/actions-gh-pages\nGitHub Pagesに公開するaction.\nExample:\n- uses:peaceiris/actions-gh-pages@v3with:github_token:${{secrets.GITHUB_TOKEN}}publish_dir:./public#publish_branch: master # default: gh-pagespeaceiris/actions-hugo https://github.com/peaceiris/actions-hugo\nランナー上にHugoをインストールする。\nExample:\n- name:SetupHugouses:peaceiris/actions-hugo@v2with:hugo-version:\u0026#39;0.68.3\u0026#39;# extended: true- name:Buildrun:hugo--minifyTips:\n extended: true でHugoの拡張版をインストール hugo-version: latest で最新版を使う  ","excerpt":"Marketplace \u0026hellip; 公開されているactionを見つけられる。  Actionとは About actions - GitHub Help\nactionはワークフローで実行される …","ref":"/tech-notes/a/web-service/github/action/action/","title":"Actions（タスク）"},{"body":"CI/CD等のワークフローを自動実行できるサービス。\n2019年11月に正式リリースされた。\nDocumentation https://help.github.com/en/actions\n Workflow syntax for GitHub Actions - GitHub Help  Getting Started https://github.com/actions/starter-workflows \u0026hellip; 初心者向けワークフローサンプル集\nWorkflowの作成 https://help.github.com/en/actions/configuring-and-managing-workflows/configuring-a-workflow\n プロジェクトの .github/workflows/ ディレクトリ下にYAMLファイルを作成する pushをトリガーにしたり、定期的に実行したりできる  See https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#on    対象branchやpathをフィルタする Example:\non:push:branches:- master- \u0026#39;releases/**\u0026#39;- \u0026#39;!releases/**-alpha\u0026#39;# alpha版は含めないtags:- v1# file paths to consider in the event. Optional; defaults to all.paths:- \u0026#39;test/*\u0026#39;paths-ignore:- \u0026#39;docs/**\u0026#39;リファレンス:\n branchやtagについて -\u0026gt; on.\u0026lt;push|pull_request\u0026gt;.\u0026lt;branches|tags\u0026gt; pathについて -\u0026gt; on.\u0026lt;push|pull_request\u0026gt;.paths  複数の実行環境に対応する 複数のOSプラットフォームや、ランタイムのバージョンに対応する方法。\n下のようなbuild matrixを設定すると良い。\nExample:\nruns-on:${{matrix.os}}strategy:matrix:os:[ubuntu-16.04,ubuntu-18.04]node:[6,8,10]変数やシークレットの利用 https://help.github.com/en/actions/configuring-and-managing-workflows/using-variables-and-secrets-in-a-workflow\nGITHUB_TOKENによる認証 Authenticating with the GITHUB_TOKEN - GitHub Help\n GitHubは、ワークフローで利用する GITHUB_TOKEN シークレットを自動的に生成します。 この GITHUB_TOKEN は、ワークフローの実行内での認証に利用できます。\n ","excerpt":"CI/CD等のワークフローを自動実行できるサービス。\n2019年11月に正式リリースされた。\nDocumentation https://help.github.com/en/actions …","ref":"/tech-notes/a/web-service/github/action/","title":"GitHub Actions"},{"body":"リファレンス https://golang.org/ref/spec\n変数 https://golang.org/ref/spec#Variables\nパッケージ変数 package foo var privateVar string = \u0026#34;this is private\u0026#34; // 外部から見えない var PublicVar string = \u0026#34;this is public\u0026#34; // 外部から見える 参考:\n Go言語のスコープについて - ryochack.clipboard  データ型 https://golang.org/ref/spec#Types\n配列・スライス 配列は固定長。スライスは可変長。\na := [...]int{1, 2, 3} // 配列  s1 := []int{1, 2, 3} // スライス s2 := []int{5, 6, 7} // スライスの結合 s1 = append(s1, 4) s1 = append(s1, s2...) // スライス同士の結合では \u0026#34;...\u0026#34; が必要 \u0026ldquo;Slicing\u0026quot;というテクニックで配列をスライスに変換できる。\na := [5]byte{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;} s := a[:] // aを参照するスライス 参考:\n Go Slices: usage and internals - The Go Blog Go言語のArrayとSliceについて - done is better than perfect Goでsliceに要素追加, slice同士の結合 - Qiita  map 初期値はnilで、データを入れようとするとパニックが起こるので、事前に割当てが必要。\n// NG var ages map[string]int ages[\u0026#34;carol\u0026#34;] = 21 // OK var ages map[string]int ages = make(map[string]int) ages[\u0026#34;carol\u0026#34;] = 21 // OK ages := make(map[string]int) ages[\u0026#34;carol\u0026#34;] = 21 要素取得時のヒット検査 age, ok := ages[\u0026#34;bob\u0026#34;] if ok { // hit } else { // miss } 構造体 初期化 // 例 type Foo struct { Name string Age int } // (1) f := Foo{} f.Name = \u0026#34;foo\u0026#34; f.Age = 5 // (2) f := Foo{\u0026#34;foo\u0026#34;, 5} // 全てのフィールドの指定が必要  // (3) f := Foo{Age: 5, Name: \u0026#34;foo\u0026#34;} // 任意フィールドの省略が可能。順番も入れ替え可能 もし構造体に初期値を設定したい場合、コンストラクタ的な専用の関数を作る必要があるっぽい。\n参考:\n [Go] 構造体の初期化方法まとめ - Qiita 【Go】structにデフォルトの値を設定したい - /dev/null  日付・時刻 日時フォーマット Go言語の日時のフォーマット関数（timeパッケージのfunc (Time) Format)）に与えられる引数は、2006-01-02T15:04:05（月曜）の日時となっている。\nこれはアメリカで時刻を表記する際の順番で、1月2日午後3時4分5秒2006年となり、わかりやすかったからだそうだ。\n参考:\n Goのtimeパッケージのリファレンスタイム（2006年1月2日）は何の日？ - Qiita  ポインタ 参考:\n Goでxxxのポインタを取っているプログラムはだいたい全部間違っている - Qiita  goroutine OSのネイティブスレッドより扱いやすくしたもの。 スレッドとファイバーの良いとこ取り。 go というキーワードを付けるとgoroutineが作られる。\nExamples:\n// 別のgoroutineを作って既存関数を実行 go Function() // 別のgoroutineを作って、無名関数を実行 go func() { // goroutine内で実行したい処理 } 参考:\n Go言語で非同期処理の結果を受け取る - Qiita  チャネル SYNOPSIS:\n// バッファなし tasks := make(chan string) // バッファ付き tasks := make(chan string, 10) // データ送信 tasks \u0026lt;- \u0026#34;cmake ..\u0026#34; tasks \u0026lt;- \u0026#34;cmake . --build Debug\u0026#34; // データ受信 task := \u0026lt;-tasks // データ受信 + クローズ判定 task, ok := \u0026lt;-tasks // データを読み捨てる \u0026lt;-wait Examples:\n https://gobyexample.com/channels  select文 複数のチャネルを待機する場合に使う。\nExamples:\n// ブロックせずに受信し、かつ、チャネルがクローズ済みかどうかチェックする select { case v, ok := \u0026lt;- ch: if ok { fmt.Println(v) } else { fmt.Println(\u0026#34;closed\u0026#34;) } default: fmt.Println(\u0026#34;no value\u0026#34;) } // ブロックせずに送信 select { case ch \u0026lt;- v: fmt.Println(\u0026#34;sent\u0026#34;) default: fmt.Println(\u0026#34;no capacity\u0026#34;) } 参考:\n Go言語でチャネルとselect - Qiita select - はじめてのGo言語  文法 ループ Examples:\nfor { // 無限ループ } for i := 1; i \u0026lt; 100; i++ { // iが[1, 100)の間 } // collection要素のイテレーション dayOfWeeks := [...]string{\u0026#34;月\u0026#34;, \u0026#34;火\u0026#34;, \u0026#34;水\u0026#34;, \u0026#34;木\u0026#34;, \u0026#34;金\u0026#34;, \u0026#34;土\u0026#34;, \u0026#34;日\u0026#34;} for arrayIndex, dayOfWeek := range dayOfWeeks { fmt.Printf(\u0026#34;%d番目の曜日は%s曜日です。\\n\u0026#34;, arrayIndex + 1, dayOfWeek) } ※mapをイテレーションする場合、取り出し順はランダムになる。\n参考:\n 繰り返し - はじめてのGo言語  パッケージ init()関数による初期化  ソースファイルに1つ func init() を記述できる ソースファイル読み込み時に1回実行される importされるpackageのinit()が先に実行される  pがqをimportしているとき、pのinit()より先にqのinit()が完了している mainパッケージのinit()が最後に実行される    参考:\n Effective Go - golang.jp  ","excerpt":"リファレンス https://golang.org/ref/spec\n変数 https://golang.org/ref/spec#Variables\nパッケージ変数 package foo var …","ref":"/tech-notes/a/program/lang/go/spec/","title":"言語仕様"},{"body":"Getting Started ドキュメント  https://golang.org/doc/  https://golang.org/doc/effective_go.html   http://golang-jp.org/ \u0026hellip; golang.orgの日本語訳プロジェクト  3rd Party がまとめた資料  GoのためのGo Go Language Programs, Tutorial, Articles and Examples  Play Ground Sandbox https://play.golang.org/\n記事  6年間におけるGoのベストプラクティス | プログラミング | POSTD  開発ツール goimports https://godoc.org/golang.org/x/tools/cmd/goimports\nInstall:\ngo get golang.org/x/tools/cmd/goimports goimports というコマンドが入る。\ngo fmt のときに使われてないpkgの import 文を削除してくれる。\nGoglandだと Settings \u0026gt; Go \u0026gt; On Save \u0026gt; On save run で設定できる。\n参考:\n goのimportを自動的に追加/削除してくれる「goimports」を試してみた - Misc Notes Gogland で保存時に go fmt を走らせる - Qiita  ビルトイン関数 append https://golang.org/pkg/builtin/#append\nfunc append(slice []Type, elems ...Type) []Type\nsliceに要素、またはsliceを結合し、新たなsliceを返す。\nslice = append(slice, elem1, elem2) slice = append(slice, anotherSlice...) Topics vendoring アプリケーションなどで、依存パッケージを管理する仕組み。\nGo 1.6から正式にサポートされた。\nGo 1.5ではexperimental扱いで、有効化するには環境変数 GO15VENDOREXPERIMENT を設定してコンパイルする必要がある。\nvendoringのためのツールとして、glideやgomなどがある。\n参考:\n 今更だけどGoのVendoringについて思いをはせる - Qiita go vendoring - 隙あらば寝る Glide で Go 言語のパッケージ管理と vendoring - Librabuch  enum Goにはenumがない。\nintの独自型を定義するのがイディオムになっている。\ntype Fruit int const ( Apple Fruit = iota Orange Banana ) var myFruit Fruit この独自型に対して String() メソッドを実装しておくと、名前が引けて便利:\nfunc (f Fruit) String() string { switch f { case Apple: return \u0026#34;Apple\u0026#34; case Orange: return \u0026#34;Orange\u0026#34; case Banana: return \u0026#34;Banana\u0026#34; default: return \u0026#34;Unknown\u0026#34; } } golang.org/x/tools/cmd/stringer で String() メソッドを含むコードを自動生成することもできる。\n参考:\n GoのEnumイディオム - Qiita Big Sky :: Re: GoLangでJavaのenumっぽいライブラリ作った話 Ten Useful Techniques in Go – Fatih Arslan https://godoc.org/golang.org/x/tools/cmd/stringer  build https://golang.org/pkg/go/build/\nBuild Constraints という機能は「build tag」としても知られている。\nこんなの:\n// (A) // +build foo  // (B) // +build !foo (A) go build -tags=foo でビルドされる。\n(B) go build でビルドされる。\n参考:\n go build -tagsを使ってRelease/Debugを切り替える - flyhigh  プロファイリング  runtime/pprofという標準pkgを使うのが基本な感じ。  その内 標準パッケージ - progrhyme\u0026rsquo;s Tech Wiki に書くと思う。   runtimeのデバッグに役立つ環境変数の話:  GODEBUG | Dave Cheney    参考:\n Profiling Go Programs - The Go Blog \u0026hellip; pprof golangで書かれたプログラムのメモリ使用状況を見る - hakobe-blog ♨ \u0026hellip; pprof, net/http/pprof golang profiling の基礎 \u0026hellip; pprof他 golangパフォーマンス3: mapとGC - Qiita  Child Pages ","excerpt":"Getting Started ドキュメント  https://golang.org/doc/  https://golang.org/doc/effective_go.html …","ref":"/tech-notes/a/program/lang/go/","title":"Go"},{"body":"https://www.docsy.dev/\nGoogleが2019年に公開したHugoのテーマ。\n事例がここに載っている。\nkubeflow, Knative, Apache Airflowなどで使われている。\n20ページ以上のドキュメントサイトを作るときに向いている、と謳っている。\n多言語対応しており、プロダクトのバージョニングも考慮されている。\nDocumentation https://www.docsy.dev/docs/\nGetting Started https://www.docsy.dev/docs/getting-started/\nHugoの拡張版が必要。\nこれはSCSSを使っているためのようだ。\n参考:\n Error building site: POSTCSS: failed to transform \u0026quot;scss/main.css\u0026quot; · Issue #235 · google/docsy  デモサイトのソースをcloneして使う ふつうのHugo Themeなら、 hugo new site してconfig.tomlでthemeを指定すれば大体それっぽく動くのだけど、Docsyはやや作りが複雑なようなので、Exampleサイトのソースを再利用した方が早そう。\ngit clone https://github.com/google/docsy-example.git mydocs cd mydocs git submodule update --init --recursive ","excerpt":"https://www.docsy.dev/\nGoogleが2019年に公開したHugoのテーマ。\n事例がここに載っている。\nkubeflow, Knative, Apache Airflowなどで使 …","ref":"/tech-notes/a/software/hugo/theme/docsy/","title":"Docsy"},{"body":"https://learn.netlify.com/en/\nドキュメンテーションに向いた高機能なHugoのテーマ。\nコンテンツ管理 ページの追加 https://themes.gohugo.io//theme/hugo-theme-learn/en/cont/archetypes/ を参照。\n# Chapterページ hugo new path/to/chapter/_index.md --kind chapter # 普通のページ hugo new path/to/page.md  NOTE パスは content/ からの相対パス。  拡張記法 いくつかHugoの機能を拡張して便利記法を提供してくれているのかな？\nShortcodesに紹介されている。\n Mermaidによるフローチャート Hugoのサイト設定変数参照 etc.  などの機能がある。\n以下は例:\n注釈 {{% notice note %}} A notice disclaimer {{% /notice %}} note 以外に、 info, tip, warning が使える。\n","excerpt":"https://learn.netlify.com/en/\nドキュメンテーションに向いた高機能なHugoのテーマ。\nコンテンツ管理 ペー …","ref":"/tech-notes/a/software/hugo/theme/learn/","title":"LEARN"},{"body":"Hugoはテーマによって、見た目やレイアウトなどをカスタマイズすることができる。\nhttps://themes.gohugo.io/ がテーマのサイトで、様々なテーマが紹介されている。\nこのサイトに自作のテーマを載せるには、 https://github.com/gohugoio/hugoThemes/blob/master/README.md#adding-a-theme-to-the-list のガイドに従ってコントリビュートすると良い。\nChild Pages ","excerpt":"Hugoはテーマによって、見た目やレイアウトなどをカスタマイズすることができる。\nhttps://themes.gohugo.io/ がテーマのサイトで、様々なテーマが紹介されている。\nこのサイトに自 …","ref":"/tech-notes/a/software/hugo/theme/","title":"Themes（テーマ）"},{"body":"4/25 技術メモ用のサイトをHugoで新設することにした 来年末には旧版のGoogleサイトが使えなくなるそうなので、早く移行しないとなー、と前々から思っていた。 今回、ようやく重い腰を上げた形。\n今時はhugoで作ったGitHub PagesのサイトはGitHub Actionで自動更新できるようだ。\n参考:\n HugoのビルドをGithub Actionで自動化する - 1ミリもわからん GitHub Actions による GitHub Pages への自動デプロイ - Qiita  …で、前々から目をつけていたHugoのテーマ「LEARN」を使うことにした。\nGoogleが去年公開したDocsyというテーマでもよさそうだと思ったけど、LEARNの方は一度軽く試したこともあったので、安心感があった。\nLEARNで気に入らなかったところ 少しHugoのLEARNテーマでサイトを作っていたのだけど、少し不満が出てきた。\n chapterページを作らないといけなくて、自由度が阻害されるように感じた。（自分でchapterページをカスタマイズするというやり方もあるが） 検索が妙にヒットしすぎる ページの目次がちょっとわかりにくい。慣れれば問題ないけど  GitBookを試してみたけど、OSS版は先行きが微妙 GitBookでもいいんじゃないかと思って試していたのだけど、残念なことに気がついた。\n詳しくはSoftware \u0026gt; GitBookに書いた。\n手順:\nnpm install -g gitbook-cli mkdir new-docs cd $_ gitbook init gitbook serve 参考にした記事:\n GitBookによるドキュメント作成 - Qiita GitBookをGitHub Pagesにアップロード | 酒と涙とRubyとRailsと gitbookの使い方 - Qiita  結局、Docsyへ azuさんがGitBookからDocusaurusに移行していたので、それもいいかもと思ったけど、見た目がDocsyに似ていたのでもうDocsyでいいだろうと思った。\n4/26 プロフィールサイトのgulpがつらい 昨日、Docsyを扱うにあたって、UbuntuマシンのNode.jsをv8 -\u0026gt; v12に上げた。\nReferenceError: primordials is not defined 今日、プロフィールサイト https://progrhy.me の編集をしようとそのまま作業していたら、次とほぼ同じ問題に遭遇した。\n Node.js v12にアップデートするとgulp v4でもfs.jsで「ReferenceError: primordials is not defined」エラーが発生 - 毎日へっぽこ  自分の環境で問題になったのは natives module.\n% gulp fs.js:35 } = primordials; ^ ReferenceError: primordials is not defined at fs.js:35:5 at req_ (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:137:5) at Object.req [as require] (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:54: 10) at Object.\u0026lt;anonymous\u0026gt; (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/vinyl-fs/node_modules/gra ceful-fs/fs.js:1:37) at Module._compile (internal/modules/cjs/loader.js:1156:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:1176:10) at Module.load (internal/modules/cjs/loader.js:1000:32) at Function.Module._load (internal/modules/cjs/loader.js:899:14) at Module.require (internal/modules/cjs/loader.js:1042:19) at require (internal/modules/cjs/helpers.js:77:18) 自分の場合も、上の記事と同じように、 package-lock.json 内に graceful-fs のv3系への依存があった。\nまた、依存の解消は難しいようだった。\n前回の挑戦から、gulpのバージョンアップは今のところ諦めているので、Node.jsのバージョンをv10系に下げることにした。\nReferenceError: internalBinding is not defined 次に出くわしたのは下のエラー:\n gulp利用時に「ReferenceError: internalBinding is not defined」のエラー - なるの備忘録  % gulp internal/util/inspect.js:31 const types = internalBinding('types'); ^ ReferenceError: internalBinding is not defined at internal/util/inspect.js:31:15 at req_ (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:137:5) at require (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:110:12) at util.js:25:21 at req_ (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:137:5) at require (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:110:12) at fs.js:42:21 at req_ (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:137:5) at Object.req [as require] (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/natives/index.js:54: 10) at Object.\u0026lt;anonymous\u0026gt; (/home/progrhyme/my/repos/progrhyme.github.io/node_modules/vinyl-fs/node_modules/gra ceful-fs/fs.js:1:37) 上の記事にあったように、 npm i natives@latest --no-save を実行したら解消した。\n","excerpt":"4/25 技術メモ用のサイトをHugoで新設することにした 来年末には旧版のGoogleサイトが使えなくなるそうなので、早く移行しないとなー、と前々から思っていた。 今回、ようやく重い腰を上げた形。\n …","ref":"/tech-notes/a/memo/20200425/","title":"2020-04-25"},{"body":"3/18 Ubuntuでkrewを使ってkubectx/kubensをinstall kubectxをUbuntuにどうやって入れようかとREADMEを見ていたら、kubectlにはkrewというプラグイン管理システムがあるそうな。\nhttps://github.com/kubernetes-sigs/krew/\nhttps://krew.sigs.k8s.io/docs/user-guide/setup/install/ に従ってインストール\n## bash ( set -x; cd \u0026#34;$(mktemp -d)\u0026#34; \u0026amp;\u0026amp; curl -fsSLO \u0026#34;https://github.com/kubernetes-sigs/krew/releases/latest/download/krew.{tar.gz,yaml}\u0026#34; \u0026amp;\u0026amp; tar zxvf krew.tar.gz \u0026amp;\u0026amp; KREW=./krew-\u0026#34;$(uname | tr \u0026#39;[:upper:]\u0026#39; \u0026#39;[:lower:]\u0026#39;)_amd64\u0026#34; \u0026amp;\u0026amp; \u0026#34;$KREW\u0026#34; install --manifest=krew.yaml --archive=krew.tar.gz \u0026amp;\u0026amp; \u0026#34;$KREW\u0026#34; update ) ↓を.bashrcに追記\nexport PATH=\u0026#34;${KREW_ROOT:-$HOME/.krew}/bin:$PATH\u0026#34; …で、kubectx/kubensをinstall:\nkubectl krew install ctx kubectl krew install ns kubectx kubens ではなく kubectl ctx kubectx ns で使うことになる。\nGKEのIngressではGCSをバックエンドにできない kubernetesを使った開発のベストプラクティスを求めて - Qiita\nこの記事は2年4ヶ月前のものなのだが、自分で試してもできなかった。\n残念。\n","excerpt":"3/18 Ubuntuでkrewを使ってkubectx/kubensをinstall kubectxをUbuntuにどうやって入れようかとREADMEを見ていたら、kubectlにはkrewというプラ …","ref":"/tech-notes/a/memo/20200318/","title":"2020-03-18"},{"body":"  #td-cover-block-0 { background-image: url(/tech-notes/featured-background_hu010825fc1acc2b06122e03e2fe511e22_325962_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/tech-notes/featured-background_hu010825fc1acc2b06122e03e2fe511e22_325962_1920x1080_fill_q75_catmullrom_top.jpg); } }  progrhyme\u0026#39;s Tech Notes IT技術についての公開メモ帳\nExplore Site   View Repository          ","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/tech-notes/","title":"progrhyme's Tech Notes"},{"body":"","excerpt":"","ref":"/tech-notes/search/","title":"検索結果"}]